---
layout: post
audiourl: /media/VidaGeek_2x11.mp3
guid: ffe0ef08-8f9e-42b1-aa01-d4a7f7806b23
season: 2
explicit: "no"
---

# Tree of thoughts: Deliberate problem solving with Large Language Models
[https://arxiv.org/pdf/2305.10601.pdf][arxiv]

Esta pasada semana se ha publicado un paper llamado “Tree of thoughts: Deliberate problem solving with Large Language Models” que sería algo como “Pensamiento arborescente: Solución de problemas con modelos grandes de lenguaje”. En este paper se explican los métodos más habituales en los que se usan los LLM como ChatGPT y se propone un nuevo método el cual mejora sustancialmente los métodos actuales.

Hasta ahora básicamente se usan 3 métodos:
 - Input-Output prompting: El cual consiste básicamente en hacer una pregunta para llegar a una respuesta. Sería lo que hacemos habitualmente con ChatGPT.
 - Chain of thought prompting: Consiste en separar la pregunta en los pasos necesarios para llegar a una respuesta, de esta manera la respuesta siempre es más efectiva. Se utiliza en algunos proyectos como BabyAGI o AutoGPT.
 - Self consistency with CoT: Que sería básicamente lo mismo que CoT pero haciendo la pregunta y elaborando los pasos varias veces de forma que nos quedaremos con la respuesta final que más se repita.

Y el paper propone un nuevo método al que llama Tree of Thoughts o Árbol de pensamientos el cual consiste en, resumiéndolo mucho, en pedir al LLM que elabore varios planes para la resolución de un problema. Luego se le pide 5 veces que vote cuál es el mejor plan para resolver el problema planteado. Una vez hecho se le vuelve a pedir que elabore varios planes para resolver el problema basándose en los planes más votados y se vuelve a establecer un sistema de votaciones para esos planes generados. De esta manera se van creando unas ramas de pensamiento y las más votadas se van siguiendo. Es posible que alguna no llegue a buen puerto y se descarte esa rama por completo volviendo a una rama anterior.

Este nuevo método parece muy efectivo y es muy prometedor. En las pruebas que han realizado han conseguido unos resultados excelentes. Por ejemplo en la resolución de crucigramas, los métodos clásicos como IO o CoT solo conseguían resolver 1 de cada 100 en el mejor de los casos mientras que ToT ha conseguido resolver 20 de cada 100. E incluso es más impresionante en el juego de 24 en el cual los métodos tradicionales conseguían un 9% de éxito mientras que ToT consigue un 74% de soluciones correctas.

Ya ha salido una implementación en Python para que se pueda probar y trastear con ello:
[https://github.com/kyegomez/tree-of-thoughts][python]

# Drag your GAN: Interactive Point-based Manipulation on the Generative Image Manifold
[https://vcai.mpi-inf.mpg.de/projects/DragGAN/][draggan]

Este paper que se podría traducir como “Arrastra tu GAN, Manipulación interactiva basada en puntos de la variedad de imágenes generativas

----

# Mandos de videojuego accesibles
Hoy os traemos unos cuantos mandos económicos para poder disfrutar de nuestros juegos sin que nos escueza el bolsillo. 

En concreto son estos modelos:
    - [Microsoft Xbox original (XBOX y PC)][mando1]
    - [Nacon - Compact Mando (PS4 y PC)][mando2]
    - [G-Lab K-Pad Thorium Mando Gaming (PS3 y PC)][mando3]
    - [Diswoe Mando Xbox 360 (PC)][mando4]
    - [PowerA (Xbox Series X|S Y PC)][mando5]


## Recomendacion
Desde mi punto de vista eligiria de todos ellos el mando POWER A por su calidad de acabado, precio y ergonomia a la hora de jugar ya que es practicamente lo mismo que el de xbox original pero con cable. Eso lo hace mas ligero pero con el incoveniente de tenerlo que tener conectado por cable.

¡Hasta la próxima semana!

[mando1]: https://amzn.to/3C0N0mo
[mando2]: https://amzn.to/3BVTR0l
[mando3]: https://amzn.to/3qiIvk9
[mando4]: https://amzn.to/3OGUySy
[mando5]: https://amzn.to/3BXoYIT
[draggan]: https://vcai.mpi-inf.mpg.de/projects/DragGAN/
[python]: https://github.com/kyegomez/tree-of-thoughts
[arxiv]: https://arxiv.org/pdf/2305.10601.pdf 
