<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://vidageek.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://vidageek.com/" rel="alternate" type="text/html" /><updated>2023-10-04T10:58:37+00:00</updated><id>https://vidageek.com/feed.xml</id><title type="html">VidaGeek</title><subtitle>Un podcast sobre tecnología, programación, videojuegos y mucho más</subtitle><entry><title type="html">Podcast 3x02</title><link href="https://vidageek.com/3/2023/10/03/podcast-3x02.html" rel="alternate" type="text/html" title="Podcast 3x02" /><published>2023-10-03T00:00:00+00:00</published><updated>2023-10-03T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/10/03/podcast-3x02</id><content type="html" xml:base="https://vidageek.com/3/2023/10/03/podcast-3x02.html"><![CDATA[<h1 id="charlando-sobre-iphone-15-macbook-air-financiación-openai-bing-meta-quest-y-más">Charlando sobre iPhone 15, Macbook Air, financiación, OpenAI, Bing, Meta Quest y más</h1>
<p>En el episodio de hoy hablamos de forma distendida sobre varias cosas como el iPhone 15 o el Macbook Air de los cuales Paco es nuevo poseedor (aún en parte). Además hablamos sobre <a href="https://github.com/jzhang38/TinyLlama">TinyLlama</a>, un nuevo LLM “pequeño” de tan sólo 1.1 billones de parámetros.</p>

<p>También os contamos lo nuevo de <a href="https://openai.com/blog/chatgpt-can-now-see-hear-and-speak">OpenAI que ahora puede oír, hablar y ver</a> y de cómo podemos utilizarlo gratis gracias a <a href="https://www.bing.com/?cc=es">Bing</a>.</p>

<p>Meta ha presentado las nuevas <a href="https://www.meta.com/es/quest/quest-3/">Quest 3</a> y han hecho un vídeo en el nos muestran cómo las podemos utilizar para entrar <a href="https://www.youtube.com/watch?v=MVYrJJNdrEg">en una videoconferencia con un avatar fotorrealista</a>. Muy interesante, la verdad.</p>

<hr />
<p>Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Charlando sobre iPhone 15, Macbook Air, financiación, OpenAI, Bing, Meta Quest y más En el episodio de hoy hablamos de forma distendida sobre varias cosas como el iPhone 15 o el Macbook Air de los cuales Paco es nuevo poseedor (aún en parte). Además hablamos sobre TinyLlama, un nuevo LLM “pequeño” de tan sólo 1.1 billones de parámetros.]]></summary></entry><entry><title type="html">Podcast 3x01</title><link href="https://vidageek.com/3/2023/09/25/podcast-3x01.html" rel="alternate" type="text/html" title="Podcast 3x01" /><published>2023-09-25T00:00:00+00:00</published><updated>2023-09-25T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/09/25/podcast-3x01</id><content type="html" xml:base="https://vidageek.com/3/2023/09/25/podcast-3x01.html"><![CDATA[<h1 id="open-interpreter-hablando-con-tu-ordenador">Open Interpreter: Hablando con tu ordenador</h1>

<p>La inteligencia artificial sigue imparable. Hoy vamos a hablar de un nuevo proyecto de código abierto llamado <a href="https://github.com/KillianLucas/open-interpreter">Open Interpreter</a> el cual nos permite “hablar” con nuestro ordenador.</p>

<p><a href="https://github.com/KillianLucas/open-interpreter">Open Interpreter</a> es la respuesta de código abierto al plugin “Code Interpreter” que sacó en la versión plus de ChatGPT. Este plugin permite la creación y ejecución de código en base a una petición, o prompt. Entre otras cosas te permite resolución de problemas matemáticos, análisis y visualización de datos, convertir ficheros a diferentes formatos, y cosas así. No obstante tiene ciertas limitaciones como que opera sin acceso a internet, tiene un set de paquetes previamente instalados limitado, tiene un límite de 2 minutos de ejecución y el estado es eliminado después de la ejecución.</p>

<p>Open Interpreter viene a mejorar todo esto, dando acceso completo a tu PC o Mac de forma que pueda ejecutar código diréctamente en tu equipo y con acceso a internet, eliminando todos esos límites impuestos por ChatGPT. Además, al ser un proyecto open source, puede operar totalmente en local utilizando un LLM que también se ejecute en local. Aunque si queremos que tenga mucha más potencia y conocimiento lo ideal es que utilicemos GPT4. No obstante en este caso estaremos enviando todo lo que hacemos a OpenAI y esto puede suponer un problema de privacidad.</p>

<p>Aquí os vamos a explicar cómo ponerlo en marcha totalmente en local, sin tener que utilizar GPT4. Para ello utilizaremos CodeLlama, un LLM desarrollado por Meta, especializado en programación, que se ejecuta en local y con una licencia bastante abierta.</p>

<h2 id="puesta-en-marcha">Puesta en marcha</h2>

<p>Lo primero que tenemos que realizar es crearnos un entorno de ejecución con Conda. Si bien este paso no es esencial, es muy recomendable. Conda es un gestor de entornos de ejecución de forma que nos crea entornos independientes para cada proyecto. Esto está muy bien ya que muchas veces los proyectos necesitan de versiones específicas de ciertos paquetes o librerías. Para ello Conda crea un entorno de ejecución para cada proyecto aislado de los demas. Si bien aquí no vamos a tratar la instalación de Conda, es algo muy sencillo de realizar haciéndo una búsqueda en internet.</p>

<p>Una vez tengamos conda instalado crearemos un entorno para el proyecto:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ conda create python=3.11 open-interpreter
 $ conda activate open-interpreter
</code></pre></div></div>

<p>El siguiente paso es simplemente instalar open-interpreter con pip:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ pip install open-interpreter
</code></pre></div></div>

<p>Y ya está! Simplemente con esto ya tenemos Open Interpreter instalado. Ahora simplemente tenemos que ejecutar</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ interpreter
</code></pre></div></div>
<p>y seguir los pasos que nos va pidiendo.</p>

<h2 id="gpt4-o-codellama">GPT4 o CodeLlama</h2>

<p>Lo primero que nos pedirá es la clave de API de OpenAI para utilizar GPT4 como motor LLM. Esto es lo más rápido y efectivo puesto que GPT4 es el LLM más potente y capaz hasta la fecha. No obstante tiene ciertas desventajas:</p>
<ul>
  <li>No es gratis</li>
  <li>Todos tus comandos y respuestas serán enviados a OpenAI para procesarlos
Como alternativa podemos usar CodeLlama. Un LLM desarrollado por Meta que podemos ejecutar en local. CodeLlama viene en 3 sabores: 7B, 11B y 34B. Cada número se refiere a los billones de parámetros que tiene el modelo. Como suele ser en estas cosas, cuanto más, mejor. Pero cuanto más, más RAM y potencia de cálculo necesitarás.</li>
</ul>

<p>He hecho pruebas con el más potente (34B aunque muy comprimido) y con GPT4 y claramente GPT4 es mucho más potente y capaz. Aunque en la petición que le hice (generar un fichero excel a partir de un listado de películas en un PDF) no fue capaz de conseguir el objetivo final.</p>

<h2 id="opencore-legacy-patcher">OpenCore Legacy Patcher</h2>

<p>Paco nos ha comentado cómo ha sido posible actualizar su Macbook Pro Retina de 2014 a la última versión de MacOS gracias a <a href="https://dortania.github.io/OpenCore-Legacy-Patcher/">OpenCore Legacy Patcher</a>, un proyecto open source que nos permite crear un instalador de MacOS que engaña al sistema operativo haciéndole creer que se está ejecutando en un hardware soportado.</p>

<p>Dependiendo del hardware que tengamos algos OS serán soportados y otros no. Sin embargo si tu equipo es de 2013 o supuerior suele poder soportar los últimos MacOS hasta la fecha. Quizá haya algunas funcionalidades que no estén disponibles pero generalmente funciona francamente bien.</p>

<hr />

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Open Interpreter: Hablando con tu ordenador]]></summary></entry><entry><title type="html">Podcast 2x14</title><link href="https://vidageek.com/2/2023/07/06/podcast-2x14.html" rel="alternate" type="text/html" title="Podcast 2x14" /><published>2023-07-06T00:00:00+00:00</published><updated>2023-07-06T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/07/06/podcast-2x14</id><content type="html" xml:base="https://vidageek.com/2/2023/07/06/podcast-2x14.html"><![CDATA[<h1 id="hubble-network-revolucionando-la-comunicación-de-dispositivos-iot-desde-el-espacio">Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio</h1>

<p>Hoy vamos a hablar de Hubble Network, una compañía que pretende revolucionar la forma en la que se comunican muchos de nuestros dispositivos, especialmente aquellos relacionados con el Internet de las Cosas (IoT). Estos dispositivos suelen enfrentar un problema importante: la comunicación con Internet, la cual requiere de sistemas costosos en términos de batería y tamaño.</p>

<h2 id="el-desafío-de-la-comunicación-en-dispositivos-iot">El desafío de la comunicación en dispositivos IoT</h2>

<p>Imaginemos dispositivos ubicados en un campo, encargados de monitorear animales o condiciones específicas. Para enviar esta información periódicamente a Internet, se requiere de un sistema de comunicación que, en la mayoría de los casos, resulta costoso en términos de batería y cobertura. Por ejemplo, si utilizáramos un modem GSM o LTE, similar a un teléfono móvil, nos enfrentaríamos a dos problemas principales: el consumo de batería y la cobertura en zonas rurales remotas, donde la señal puede ser escasa o inexistente.</p>

<p>Existen otros sistemas más eficientes energéticamente, como SIGFOX o LORAWAN, pero su despliegue depende de la presencia de repetidores de estos protocolos en las cercanías. En algunas zonas, puede que estos repetidores no estén disponibles.</p>

<h2 id="la-revolución-de-hubble-network">La revolución de Hubble Network</h2>

<p>Es aquí donde Hubble Network busca revolucionar estos sistemas de comunicación de una forma sencilla y eficiente. Esta empresa tiene como objetivo llevar los dispositivos BLE (Bluetooth Low Energy) al espacio. Si estás escuchando este podcast con unos AirPods u otros auriculares inalámbricos, es muy probable que estés utilizando la tecnología BLE, la cual permite una conexión fácil entre estos dispositivos y nuestros móviles.</p>

<p>Hubble Network ha desarrollado un satélite con miles de antenas modificadas para capturar las señales de los dispositivos BLE que, con un firmware específico, transmiten desde la Tierra. Esta capacidad es impresionante, ya que elimina la necesidad de utilizar chips o módems especiales como SIGFOX o LORAWAN. La mayoría de los dispositivos de IoT ya cuentan con un chip BLE, y si no lo tienen, su incorporación resulta increíblemente económica y eficiente.</p>

<p>Por ejemplo, en un proyecto en el que he estado trabajando, se utilizó un sistema similar con un chip BLE de Nordic Semi, capaz de funcionar durante 2 años con una simple pila de botón. Un ejemplo conocido de este sistema es el AirTag de Apple, cuya autonomía también es muy alta.</p>

<h2 id="la-constelación-de-satélites-de-hubble-network">La constelación de satélites de Hubble Network</h2>

<p>Hubble Network planea poner en órbita baja una constelación de satélites que capturarán la información enviada por dispositivos Bluetooth. La empresa ha conseguido una inversión de 20 millones de dólares, lo cual le permitirá lanzar su primer satélite en enero de 2024, gracias a SpaceX, y comenzar a operar su red.</p>

<p>Durante los primeros meses, con un único satélite en órbita, se espera que la captura de datos de los dispositivos ocurra cada 6 horas, el tiempo que tardará en dar una vuelta completa alrededor de nuestro planeta. A pesar de las limitaciones iniciales, esto es un logro impresionante para el inicio de esta ambiciosa empresa. Seguiremos de cerca los avances de Hubble Network y os mantendremos informados sobre su desarrollo.</p>

<p>Si tengo la oportunidad de obtener el kit de desarrollo de esta tecnología, lo utilizaré para explorar su funcionamiento. Tengo muchas ganas de presenciar cómo Hubble Network está transformando la forma en que se comunican los dispositivos IoT desde el espacio.</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio]]></summary></entry><entry><title type="html">Podcast 2x13</title><link href="https://vidageek.com/2/2023/06/11/podcast-2x13.html" rel="alternate" type="text/html" title="Podcast 2x13" /><published>2023-06-11T00:00:00+00:00</published><updated>2023-06-11T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/06/11/podcast-2x13</id><content type="html" xml:base="https://vidageek.com/2/2023/06/11/podcast-2x13.html"><![CDATA[<h1 id="la-visión-de-apple">La visión de Apple</h1>
<p>Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.</p>

<p>Y es que las nuevas gafas de Apple definen el futuro de la computación, o como ellos lo han llamado, la computación espacial. Un futuro en el que la pantalla no nos limitará en la interacción sino que podremos ampliarla o reducirla a nuestro antojo. O poner 3 pantallas si queremos.</p>

<p>Finalmente todas las especificaciones filtradas se cumplieron y tenemos unas gafas que tinen una pantalla superior a 4K en cada ojo con una densidad de píxeles superior a los 4000ppp, un procesador M2 junto a un coprocesador R1 que se encarga de la gestión de todos los sensores, que no son pocos. 12 cámaras, 6 micrófonos, seguimiento ocular y seguimiento de manos.</p>

<p>Estas gafas nos permiten crear un entorno virtual junto a nuestro entorno físico e interactuar con el mismo. Para ello no utilizamos controles externos sino que simplemente utilizamos nuestra vista y nuestras manos. Miramos lo que queremos seleccionar y pellizcamos con los dedos.</p>

<p>También tiene una corona digital con la cual controlaremos el nivel de inmersión en el sistema pudiendo ocultar por completo nuestro entorno real.</p>

<p>Además tiene una pantalla exterior en 3D que permite ver una recreación simulada de nuestros ojos de forma que da la sensación de que las gafas son transparentes.</p>

<p>La integración con el ecosistema es espectacular de forma que podemos “sacar” la pantalla de un Macbook y representarla en el espacio.</p>

<p>Lo malo es el precio, a partir de 3500$ más impuestos y sólo se pondrá a la venta en USA a partir del año que viene.</p>

<p>Tenemos muchas ganas de probarlas y veremos si somos capaces con hacernos con unas.</p>

<p>¡Un saludo y hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[La visión de Apple Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.]]></summary></entry><entry><title type="html">Podcast 2x12</title><link href="https://vidageek.com/2/2023/06/03/podcast-2x12.html" rel="alternate" type="text/html" title="Podcast 2x12" /><published>2023-06-03T00:00:00+00:00</published><updated>2023-06-03T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/06/03/podcast-2x12</id><content type="html" xml:base="https://vidageek.com/2/2023/06/03/podcast-2x12.html"><![CDATA[<h1 id="según-esta-filtración-las-gafas-de-apple-tendían-unas-especificaciones-loquísimas">Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas</h1>
<p>Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:</p>

<ul>
  <li>Pantalla Micro-OLED de 1,41 pulgadas para cada ojo</li>
  <li>Resolución 4K en cada ojo</li>
  <li>Densidad de píxeles de 4000 ppi (puntos por pulgada)</li>
  <li>Más de 5000 nits de brillo</li>
  <li>ProMotion display hasta 120hz de refresco</li>
</ul>

<p>En comparación las PlayStation VR2 tienen unas pantallas de 2000x2400 pixeles (frente a 3840x2160 del 4K) y una densidad de píxeles de 850ppi…</p>

<p>Así se explica que hubiera otro rumor que situaba su precio en unos 3000$…</p>

<p>Fuente: <a href="https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter">https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter</a></p>

<h3 id="por-cierto-que-el-lunes-a-partir-de-las-1845-hora-española-daremos-cobertura-en-directo-al-evento-de-apple">Por cierto que el lunes a partir de las 18:45 hora española daremos cobertura en directo al evento de Apple.</h3>
<h2 id="suscríbete-a-nuestro-canal-de-youtube-para-verlo-en-directo-httpswwwyoutubecomliveskn2xcvt0lofeatureshareaa">Suscríbete a nuestro canal de YouTube para verlo en directo: <a href="https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share">https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share</a>aa</h2>

<hr />

<h1 id="imagebind-un-embedding-para-enlazarlos-a-todos">ImageBind un embedding para enlazarlos a todos</h1>
<p>Meta sigue dándonos muchas alegrías ya que ha presentado un nuevo modelo de IA que pretende enlazar múltiples y diversos fuentes de datos como:</p>
<ul>
  <li>Audio</li>
  <li>Texto</li>
  <li>Imagen</li>
  <li>Datos de profundidad</li>
  <li>Datos de aceleración</li>
  <li>Mapas de calor</li>
</ul>

<p>Este nuevo modelo multimodal crea unos embeddings que interrelacionan todos los datos aunque sean de diferente tipo. De este modo se le puede pasar un audio de un perro ladrando y encontrar imágenes de perros por ejemplo. Esto abre un nuevo campo en la IA ya que enlazándolo con los grandes modelos de lenguaje LLM nos permitrá una interacción multimodal tremenda.</p>

<p>Además, es de código abierto. Meta nos está sorprendiendo mucho en este campo y dejando atrás esa mala imagen que Facebook consiguió.</p>

<p><a href="https://imagebind.metademolab.com">https://imagebind.metademolab.com</a></p>

<hr />

<h1 id="mitigar-el-riesgo-de-extinción-humana-por-ia-debería-ser-una-prioridad-global">Mitigar el riesgo de extinción humana por IA debería ser una prioridad global</h1>
<p>Esto es lo que han dicho algunas figuras relevantes en el campo de la IA como los ganadores del premio Turing Geoffery Hinton y Yoshua Bengio así como el CEO de OpenAI Sam Altman, y otros ejecutivos de OpenAI como Ilya Sutskever y Mira Murati. Además también lo suscriben el CEO de DeepMind Demis Hassabis o el CEO de Anthropic Dario Amodei, y profesores de la UC Berkely, Stanford y MIT.</p>

<p>Esta vez no han escrito una <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">carta abierta</a> como sucedió en el pasado mes de marzo, sino que simplemente han dicho lo siguiente:</p>

<blockquote>
  <p><em>“Mitigar el riesgo de extinción por la IA debería ser una prioridad global junto con otros riesgos a escala social como las pandemias o las guerras nucleares.”</em></p>
</blockquote>

<p>Más información: <a href="https://www.safe.ai/press-release">https://www.safe.ai/press-release</a></p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:]]></summary></entry><entry><title type="html">Podcast 2x11</title><link href="https://vidageek.com/2/2023/05/27/podcast-2x11.html" rel="alternate" type="text/html" title="Podcast 2x11" /><published>2023-05-27T00:00:00+00:00</published><updated>2023-05-27T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/05/27/podcast-2x11</id><content type="html" xml:base="https://vidageek.com/2/2023/05/27/podcast-2x11.html"><![CDATA[<h1 id="tree-of-thoughts-deliberate-problem-solving-with-large-language-models">Tree of thoughts: Deliberate problem solving with Large Language Models</h1>
<p><a href="https://arxiv.org/pdf/2305.10601.pdf">https://arxiv.org/pdf/2305.10601.pdf</a></p>

<p>Esta pasada semana se ha publicado un paper llamado “Tree of thoughts: Deliberate problem solving with Large Language Models” que sería algo como “Pensamiento arborescente: Solución de problemas con modelos grandes de lenguaje”. En este paper se explican los métodos más habituales en los que se usan los LLM como ChatGPT y se propone un nuevo método el cual mejora sustancialmente los métodos actuales.</p>

<p>Hasta ahora básicamente se usan 3 métodos:</p>
<ul>
  <li>Input-Output prompting: El cual consiste básicamente en hacer una pregunta para llegar a una respuesta. Sería lo que hacemos habitualmente con ChatGPT.</li>
  <li>Chain of thought prompting: Consiste en separar la pregunta en los pasos necesarios para llegar a una respuesta, de esta manera la respuesta siempre es más efectiva. Se utiliza en algunos proyectos como BabyAGI o AutoGPT.</li>
  <li>Self consistency with CoT: Que sería básicamente lo mismo que CoT pero haciendo la pregunta y elaborando los pasos varias veces de forma que nos quedaremos con la respuesta final que más se repita.</li>
</ul>

<p>Y el paper propone un nuevo método al que llama Tree of Thoughts o Árbol de pensamientos el cual consiste en, resumiéndolo mucho, en pedir al LLM que elabore varios planes para la resolución de un problema. Luego se le pide 5 veces que vote cuál es el mejor plan para resolver el problema planteado. Una vez hecho se le vuelve a pedir que elabore varios planes para resolver el problema basándose en los planes más votados y se vuelve a establecer un sistema de votaciones para esos planes generados. De esta manera se van creando unas ramas de pensamiento y las más votadas se van siguiendo. Es posible que alguna no llegue a buen puerto y se descarte esa rama por completo volviendo a una rama anterior.</p>

<p>Este nuevo método parece muy efectivo y es muy prometedor. En las pruebas que han realizado han conseguido unos resultados excelentes. Por ejemplo en la resolución de crucigramas, los métodos clásicos como IO o CoT solo conseguían resolver 1 de cada 100 en el mejor de los casos mientras que ToT ha conseguido resolver 20 de cada 100. E incluso es más impresionante en el juego de 24 en el cual los métodos tradicionales conseguían un 9% de éxito mientras que ToT consigue un 74% de soluciones correctas.</p>

<p>Ya ha salido una implementación en Python para que se pueda probar y trastear con ello:
<a href="https://github.com/kyegomez/tree-of-thoughts">https://github.com/kyegomez/tree-of-thoughts</a></p>

<h1 id="drag-your-gan-interactive-point-based-manipulation-on-the-generative-image-manifold">Drag your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</h1>
<p><a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/">https://vcai.mpi-inf.mpg.de/projects/DragGAN/</a></p>

<p>Este paper que se podría traducir como “Arrastra tu GAN, Manipulación interactiva basada en puntos de la variedad de imágenes generativas</p>

<hr />

<h1 id="mandos-de-videojuego-accesibles">Mandos de videojuego accesibles</h1>
<p>Hoy os traemos unos cuantos mandos económicos para poder disfrutar de nuestros juegos sin que nos escueza el bolsillo.</p>

<p>En concreto son estos modelos:
    - <a href="https://amzn.to/3C0N0mo">Microsoft Xbox original (XBOX y PC)</a>
    - <a href="https://amzn.to/3BVTR0l">Nacon - Compact Mando (PS4 y PC)</a>
    - <a href="https://amzn.to/3qiIvk9">G-Lab K-Pad Thorium Mando Gaming (PS3 y PC)</a>
    - <a href="https://amzn.to/3OGUySy">Diswoe Mando Xbox 360 (PC)</a>
    - <a href="https://amzn.to/3BXoYIT">PowerA (Xbox Series X|S Y PC)</a></p>

<h2 id="recomendacion">Recomendacion</h2>
<p>Desde mi punto de vista eligiria de todos ellos el mando POWER A por su calidad de acabado, precio y ergonomia a la hora de jugar ya que es practicamente lo mismo que el de xbox original pero con cable. Eso lo hace mas ligero pero con el incoveniente de tenerlo que tener conectado por cable.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Tree of thoughts: Deliberate problem solving with Large Language Models https://arxiv.org/pdf/2305.10601.pdf]]></summary></entry><entry><title type="html">Podcast 2x10</title><link href="https://vidageek.com/2/2023/05/20/podcast-2x10.html" rel="alternate" type="text/html" title="Podcast 2x10" /><published>2023-05-20T00:00:00+00:00</published><updated>2023-05-20T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/05/20/podcast-2x10</id><content type="html" xml:base="https://vidageek.com/2/2023/05/20/podcast-2x10.html"><![CDATA[<h1 id="habla-con-tus-documentos">Habla con tus documentos</h1>
<p>Esta semana os explicamos cómo hablar con vuestros documentos. Para ello hacemos uso de diferentes herramientas como <a href="https://www.chatpdf.com?via=vidageek">ChatPDF</a> o <a href="https://github.com/imartinez/privateGPT">PrivateGPT</a>.</p>

<p>El modo como funcionan estas herramientas se divide en 3 partes:</p>

<ul>
  <li>
    <p>Extracción de texto
El primer paso es extraer todo el texto del documento y categorizarlo con metadatos como número de página, autor, etc.</p>
  </li>
  <li>
    <p>Extraer embeddings del texto
Este paso utiliza un modelo que analiza semánticamente el texto y lo convierte a vectores de forma que puede ser indexado en una base de datos vectorial como <a href="https://pinecone.io">Pinecone</a> o similar.</p>
  </li>
  <li>
    <p>“Conversar” con el documento
Este último paso realiza el paso anterior por cada consulta que le realicemos. Es decir, genera embeddings de la consulta que queremos hacer para luego poder hacer una búsqueda en la base de datos de forma que encontrará los textos que se acerquen más de forma semántica a la consulta para utilizarlos como contexto o referencia en la consulta final.</p>
  </li>
</ul>

<h2 id="chatpdf">ChatPDF</h2>
<p><a href="https://www.chatpdf.com?via=vidageek">ChatPDF</a> es una herramienta online que utiliza por detrás los modelos de lenguaje de <a href="https://openai.com">OpenAI</a> como ChatGPT para las consultas o ADA para los embeddings. Es un servicio gratuito con limitaciones de hasta 120 páginas por documento o 3 documentos por día. Es muy sencilla de utilizar pero como inconveniente tiene que todo es procesdo online de forma que, si trabajamos con documentos sensibles o confidenciales, no deberíamos utilizarla.</p>

<h2 id="privategpt">PrivateGPT</h2>
<p>Por el contrario el proyecto <a href="https://github.com/imartinez/privateGPT">PrivateGPT</a> utiliza un modelo de lenguaje de código abierto que se ejecuta en local, directamente en tu CPU. Esto tiene la gran ventaja de que podemos trabajar con documentos confidenciales pero como contrapartida es mucho más lento, dependiendo en gran medida de la potencia de la CPU.</p>

<p>Como ejemplo os hemos puesto un <a href="https://colab.research.google.com/drive/1ikKWtOx73NirUjf72mNHJt_Q9uKI7m61#scrollTo=rV2Ydj-tqX-P">Google Colab</a> para que podáis probarlo aunque os adelantamos que es especialmente lento al usar sólo la CPU…</p>

<hr />
<h1 id="amazfit-gtr-4-y-gts-4">Amazfit GTR 4 y GTS 4</h1>

<h2 id="acerca-de-estos-relojes">Acerca de estos relojes</h2>
<p>Dos relojes muy similares por dentro pero muy diferentes por fuera.
El <a href="https://amzn.to/3WmkgO4">Amazfit GTR 4</a> cuenta con una pantalla HD amoled de 1.43 pulgadas con una resolucion de 466x466 Pixeles. Cuenta además con una batería que prometen durar unos 15 días. Con sensores para deporte con 150 modos de entrenamiento, control del sueño etc. Una opcion muy buena para el dia a dia y con un tamaño y forma muy deportivo</p>

<p>Por otro lado, el <a href="https://amzn.to/3pWDVbs">Amazfit GTS 4</a>, al contrario que su hermano, es rectangular(el gtr es redondo) y es la mayor diferencia que podemos encontrar en el dado que sus sensores son iguales. El peso tambien al ser mas pequeño es menor, la bateria pasa lo mismo pero no por ello malo ni mucho menos.</p>

<p>Cuenta con una pantalla de 1.75 pulgadas, comentamos en directo que la pantalla del gtr 4 era mas grande pero como dicen los datos lo dijimos mal.</p>

<p>En ambos casos hay que usar la aplicacion de Amazfit para poder usar las funcionalidades del mismo con nuestro telefono movil.
Dos opciones de relojes muy recomentadables y mucho mas asequible que otras marcas y desde luego para el dia a dia no dudaria en comprarmelo</p>

<h2 id="ventajas">Ventajas</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Bateria
- Pantalla
- Precio
</code></pre></div></div>

<h2 id="desventajas">Desventajas</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- No cuenta con NFC
- Fácil de rallar
- Aplicacion de terceros 
</code></pre></div></div>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Habla con tus documentos Esta semana os explicamos cómo hablar con vuestros documentos. Para ello hacemos uso de diferentes herramientas como ChatPDF o PrivateGPT.]]></summary></entry><entry><title type="html">Podcast 2x09</title><link href="https://vidageek.com/2/2023/05/13/podcast-2x09.html" rel="alternate" type="text/html" title="Podcast 2x09" /><published>2023-05-13T00:00:00+00:00</published><updated>2023-05-13T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/05/13/podcast-2x09</id><content type="html" xml:base="https://vidageek.com/2/2023/05/13/podcast-2x09.html"><![CDATA[<h1 id="cómo-esconder-mensajes-secretos-a-plena-vista">Cómo esconder mensajes secretos a plena vista</h1>
<p>Esta semana os vamos a hablar de la esteganografía, el arte de esconder mensajes a plena vista. Imagina que quieres enviar un mensaje secreto a tu mejor amigo, pero no quieres que tus hermanos o compañeros de clase lo lean. Entonces, en lugar de escribir el mensaje en un papel y ponerlo en un sobre, decides esconderlo dentro de un dibujo o una foto para que nadie sospeche que hay algo más. Eso es la esteganografía: esconder un mensaje dentro de otra cosa para que nadie se dé cuenta de que está ahí.</p>

<h2 id="etimología">Etimología</h2>
<p>La palabra “esteganografía” proviene de dos palabras griegas: “steganos” (στεγανός) y “graphein” (γράφειν). “Steganos” significa “cubierto” o “escondido”, mientras que “graphein” significa “escribir” o “dibujar”. Por lo tanto, la etimología de “esteganografía” se traduce aproximadamente como “escritura escondida” o “escritura encubierta”, lo que refleja la idea de ocultar mensajes secretos dentro de otros medios, como imágenes, textos o archivos de audio.</p>

<h2 id="tipos-de-esteganografía">Tipos de esteganografía</h2>
<p>Hay diferentes tipos de esteganografía, dependiendo de en qué escondes el mensaje:</p>

<ul>
  <li>
    <p>Esteganografía en imágenes: Escondes el mensaje dentro de una foto o un dibujo, cambiando un poquito los colores o los detalles de la imagen.</p>
  </li>
  <li>
    <p>Esteganografía en audio: Puedes esconder el mensaje dentro de una grabación de música o sonido, cambiando un poquito las ondas de sonido.</p>
  </li>
  <li>
    <p>Esteganografía en texto: Aquí, escondes el mensaje dentro de un texto, utilizando letras o palabras extrañas, o cambiando el tamaño y el color de las letras.</p>
  </li>
  <li>
    <p>Esteganografía en redes: En este caso, escondes el mensaje en la forma en que se envían los datos por internet u otras redes, para que no se pueda saber qué información se está compartiendo.</p>
  </li>
</ul>

<h2 id="historia">Historia</h2>
<p>La esteganografía se ha utilizado desde hace mucho tiempo. La primera vez que se tiene constancia de su uso fue en la antigua Grecia, alrededor del año 440 a.C. Un famoso general griego llamado Histiaeus quería enviar un mensaje secreto a uno de sus aliados. Entonces, afeitó la cabeza de uno de sus mensajeros, escribió el mensaje en su cuero cabelludo y esperó a que el cabello volviera a crecer. Cuando el cabello del mensajero creció lo suficiente para cubrir el mensaje, lo envió a entregar el mensaje secreto. Al llegar a su destino, el aliado volvió a afeitar la cabeza del mensajero y pudo leer el mensaje oculto.</p>

<h2 id="tutorial-esconde-un-mensaje-en-una-imagen-jpeg">Tutorial: esconde un mensaje en una imagen JPEG</h2>
<p>Para este tutorial vamos a hacer uso de un cuaderno que hemos creado de una forma sencilla.</p>

<ul>
  <li>Ocultar mensaje: <a href="https://colab.research.google.com/drive/1B5oYFHjQQZ7DJckB9HLm6U4GmKEFo0fn">Esteganografía en JPG ocultar mensaje</a></li>
  <li>Revelar mensaje: <a href="https://colab.research.google.com/drive/180wShYdVHgPU8WPBfxrWAkJnYpglSOr_">Esteganografía en JPG revelar mensaje</a></li>
</ul>

<hr />
<h1 id="legion-pro-7i-gen-8-el-ordenador-ideal-para-gamers-exigentes">Legion Pro 7i Gen 8: El ordenador ideal para gamers exigentes</h1>

<p>El <a href="https://amzn.to/3MnkXTP">Legion Pro 7i Gen 8</a> es un ordenador diseñado específicamente para disfrutar de tus videojuegos favoritos. Con una pantalla de excelente calidad y una tarjeta gráfica de última generación, podrás jugar a cualquier juego con una calidad altísima. La única desventaja es su batería, que puede durar menos de una hora, por lo que es recomendable tenerlo siempre conectado a la corriente para que la GPU funcione a pleno rendimiento. Además, cuenta con un teclado retroiluminado RGB que permite multitud de combinaciones. En definitiva, una elección TOP para juegos que durará muchos años gracias a sus 32 GB de RAM, 1 TB de disco SSD y 12 GB de gráfica RTX 4070. Debido a que está pensado para rendimiento, su tamaño y peso son amplios para garantizar una buena refrigeración y evitar que los componentes sufran en exceso. Sin duda, Lenovo está haciendo un trabajo estupendo con esta gama Legion.</p>

<h2 id="ventajas">Ventajas</h2>
<ul>
  <li>Pantalla de 16” a 240 Hz que ofrece una experiencia de juego incomparable.</li>
  <li>Tarjeta gráfica de última generación RTX 4070 de 12 GB que permite jugar a cualquier juego con una calidad altísima.</li>
  <li>Procesador Intel i9 para una mayor rapidez y eficiencia.</li>
</ul>

<h2 id="desventajas">Desventajas</h2>
<ul>
  <li>Batería de poca duración, por lo que es recomendable tenerlo conectado a la corriente para poder jugar sin problemas.</li>
  <li>Tamaño y peso elevados debido a su diseño enfocado en la refrigeración.</li>
  <li>Precio elevado, aunque su calidad lo convierte en una inversión a largo plazo para los gamers más exigentes.</li>
</ul>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Cómo esconder mensajes secretos a plena vista Esta semana os vamos a hablar de la esteganografía, el arte de esconder mensajes a plena vista. Imagina que quieres enviar un mensaje secreto a tu mejor amigo, pero no quieres que tus hermanos o compañeros de clase lo lean. Entonces, en lugar de escribir el mensaje en un papel y ponerlo en un sobre, decides esconderlo dentro de un dibujo o una foto para que nadie sospeche que hay algo más. Eso es la esteganografía: esconder un mensaje dentro de otra cosa para que nadie se dé cuenta de que está ahí.]]></summary></entry><entry><title type="html">Podcast 2x08</title><link href="https://vidageek.com/2/2023/05/06/podcast-2x08.html" rel="alternate" type="text/html" title="Podcast 2x08" /><published>2023-05-06T00:00:00+00:00</published><updated>2023-05-06T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/05/06/podcast-2x08</id><content type="html" xml:base="https://vidageek.com/2/2023/05/06/podcast-2x08.html"><![CDATA[<h1 id="cómo-generar-imágenes-geniales-con-ia">Cómo generar imágenes geniales con IA</h1>
<p>Si ya hemos visto cómo generar audio con IA y cómo hablar con un modelo de lenguaje, esta semana os traemos cómo generar imágenes con IA. Hablaremos de <a href="https://openai.com/research/dall-e">Dall-E</a>, una herramienta de <a href="https://openai.com">OpenAI</a> y una de las primeras en la generación de imágenes. También probaremos <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">Stable Difussion</a> y <a href="https://www.bluewillow.ai">BlueWillow</a> para comparar cómo generan imágenes cada una de ellas.</p>

<p>Después hablamos sobre un nuevo proyecto de código abierto que ha irrumpido en escena llamado <a href="https://github.com/deep-floyd/IF">IF de DeepFloyd</a> el cual ha sido el primero en ser capaz de generar imágenes en las cuales podemos pedir que añada un texto y éste aparecerá en la imagen de forma correcta. Hasta ahora las imágenes generadas en otras herramientas eran incapaces de generar el texto de forma coherente.</p>

<h2 id="star-wars-jedi-survivor">Star Wars Jedi: Survivor</h2>
<p>Os traemos un nuevo juego de acción y aventuras en tercera persona desarrollado por Respawn Entertainment y publicado por Electronic Arts. El juego se lanzó el 26 de abril de 2023 para PlayStation 5, Xbox Series X/S y PC. El juego sigue la historia de Cal Kestis, un joven Padawan Jedi que sobrevivió a la Orden 66 y ahora vive como un fugitivo en la galaxia. El juego ha recibido críticas positivas por su jugabilidad, historia y gráficos. IGN le dio al juego una puntuación de 9/10, mientras que PC Gamer le dio una puntuación de 8/10. The Guardian le dio al juego una puntuación perfecta de 5 estrellas. Sin embargo, el juego también ha sido criticado por sus problemas técnicos y problemas de velocidad de fotogramas.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Cómo generar imágenes geniales con IA Si ya hemos visto cómo generar audio con IA y cómo hablar con un modelo de lenguaje, esta semana os traemos cómo generar imágenes con IA. Hablaremos de Dall-E, una herramienta de OpenAI y una de las primeras en la generación de imágenes. También probaremos Stable Difussion y BlueWillow para comparar cómo generan imágenes cada una de ellas.]]></summary></entry><entry><title type="html">Podcast 2x07</title><link href="https://vidageek.com/2/2023/04/29/podcast-2x07.html" rel="alternate" type="text/html" title="Podcast 2x07" /><published>2023-04-29T00:00:00+00:00</published><updated>2023-04-29T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/04/29/podcast-2x07</id><content type="html" xml:base="https://vidageek.com/2/2023/04/29/podcast-2x07.html"><![CDATA[<h1 id="olvídate-del-backend-con-appwrite">Olvídate del backend con AppWrite</h1>
<p>Hoy hablamos sobre <a href="[https://appwrite.io]">AppWrite</a>, un proyecto de código abierto para crear tu backend de una forma fácil y rápida. Puedes instalar <a href="[https://appwrite.io]">AppWrite</a> en tu servidor utilizando docker o directamente utilizando AppWrite Cloud y de esta forma no tener que preocuparte de absolutamente nada.</p>

<p>Puedes integrar AppWrite con cualquier plataforma con sus SDKs para cualquier lenguaje de programación o framework como Flutter, iOS, Android, JS, etc.</p>

<h2 id="unrecord-videojuego-con-unreal-engine-5">Unrecord Videojuego con Unreal Engine 5</h2>
<p>Unrecord será uno de los primeros juegos en utilizar el nuevo motor de imagen Unreal Engine 5. Promete ser mucho mas realista (cosa que veremos) y mucho más espectacular en cuanto a imagen. Nos pondremos en la piel de un policía visto desde la camara que llevan en el hombro como si de una gopro se tratara. Sin duda una vista algo inusual para un juego de disparos pero que desde luego le da una sensación de realismo brutal.</p>

<p>Actualmente está en desarrollo y en principio solo saldrá para PC. Podéis seguirlo en <a href="https://store.steampowered.com/app/2381520/Unrecord/">Steam</a> o en su <a href="https://discord.com/invite/3xFRSXuDgDfork">Discord</a>. Además podéis ver un <a href="https://www.youtube.com/watch?v=IK76q13Aqt0">vídeo de demostración en YouTube</a>.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Olvídate del backend con AppWrite Hoy hablamos sobre AppWrite, un proyecto de código abierto para crear tu backend de una forma fácil y rápida. Puedes instalar AppWrite en tu servidor utilizando docker o directamente utilizando AppWrite Cloud y de esta forma no tener que preocuparte de absolutamente nada.]]></summary></entry></feed>