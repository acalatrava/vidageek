<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://vidageek.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://vidageek.com/" rel="alternate" type="text/html" /><updated>2023-07-06T13:56:43+00:00</updated><id>https://vidageek.com/feed.xml</id><title type="html">VidaGeek</title><subtitle>Un podcast sobre tecnología, programación, videojuegos y mucho más</subtitle><entry><title type="html">Podcast 2x14</title><link href="https://vidageek.com/2023/07/06/podcast-2x14.html" rel="alternate" type="text/html" title="Podcast 2x14" /><published>2023-07-06T00:00:00+00:00</published><updated>2023-07-06T00:00:00+00:00</updated><id>https://vidageek.com/2023/07/06/podcast-2x14</id><content type="html" xml:base="https://vidageek.com/2023/07/06/podcast-2x14.html"><![CDATA[<h1 id="hubble-network-revolucionando-la-comunicación-de-dispositivos-iot-desde-el-espacio">Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio</h1>

<p>Hoy vamos a hablar de Hubble Network, una compañía que pretende revolucionar la forma en la que se comunican muchos de nuestros dispositivos, especialmente aquellos relacionados con el Internet de las Cosas (IoT). Estos dispositivos suelen enfrentar un problema importante: la comunicación con Internet, la cual requiere de sistemas costosos en términos de batería y tamaño.</p>

<h2 id="el-desafío-de-la-comunicación-en-dispositivos-iot">El desafío de la comunicación en dispositivos IoT</h2>

<p>Imaginemos dispositivos ubicados en un campo, encargados de monitorear animales o condiciones específicas. Para enviar esta información periódicamente a Internet, se requiere de un sistema de comunicación que, en la mayoría de los casos, resulta costoso en términos de batería y cobertura. Por ejemplo, si utilizáramos un modem GSM o LTE, similar a un teléfono móvil, nos enfrentaríamos a dos problemas principales: el consumo de batería y la cobertura en zonas rurales remotas, donde la señal puede ser escasa o inexistente.</p>

<p>Existen otros sistemas más eficientes energéticamente, como SIGFOX o LORAWAN, pero su despliegue depende de la presencia de repetidores de estos protocolos en las cercanías. En algunas zonas, puede que estos repetidores no estén disponibles.</p>

<h2 id="la-revolución-de-hubble-network">La revolución de Hubble Network</h2>

<p>Es aquí donde Hubble Network busca revolucionar estos sistemas de comunicación de una forma sencilla y eficiente. Esta empresa tiene como objetivo llevar los dispositivos BLE (Bluetooth Low Energy) al espacio. Si estás escuchando este podcast con unos AirPods u otros auriculares inalámbricos, es muy probable que estés utilizando la tecnología BLE, la cual permite una conexión fácil entre estos dispositivos y nuestros móviles.</p>

<p>Hubble Network ha desarrollado un satélite con miles de antenas modificadas para capturar las señales de los dispositivos BLE que, con un firmware específico, transmiten desde la Tierra. Esta capacidad es impresionante, ya que elimina la necesidad de utilizar chips o módems especiales como SIGFOX o LORAWAN. La mayoría de los dispositivos de IoT ya cuentan con un chip BLE, y si no lo tienen, su incorporación resulta increíblemente económica y eficiente.</p>

<p>Por ejemplo, en un proyecto en el que he estado trabajando, se utilizó un sistema similar con un chip BLE de Nordic Semi, capaz de funcionar durante 2 años con una simple pila de botón. Un ejemplo conocido de este sistema es el AirTag de Apple, cuya autonomía también es muy alta.</p>

<h2 id="la-constelación-de-satélites-de-hubble-network">La constelación de satélites de Hubble Network</h2>

<p>Hubble Network planea poner en órbita baja una constelación de satélites que capturarán la información enviada por dispositivos Bluetooth. La empresa ha conseguido una inversión de 20 millones de dólares, lo cual le permitirá lanzar su primer satélite en enero de 2024, gracias a SpaceX, y comenzar a operar su red.</p>

<p>Durante los primeros meses, con un único satélite en órbita, se espera que la captura de datos de los dispositivos ocurra cada 6 horas, el tiempo que tardará en dar una vuelta completa alrededor de nuestro planeta. A pesar de las limitaciones iniciales, esto es un logro impresionante para el inicio de esta ambiciosa empresa. Seguiremos de cerca los avances de Hubble Network y os mantendremos informados sobre su desarrollo.</p>

<p>Si tengo la oportunidad de obtener el kit de desarrollo de esta tecnología, lo utilizaré para explorar su funcionamiento. Tengo muchas ganas de presenciar cómo Hubble Network está transformando la forma en que se comunican los dispositivos IoT desde el espacio.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio]]></summary></entry><entry><title type="html">Podcast 2x13</title><link href="https://vidageek.com/2023/06/11/podcast-2x13.html" rel="alternate" type="text/html" title="Podcast 2x13" /><published>2023-06-11T00:00:00+00:00</published><updated>2023-06-11T00:00:00+00:00</updated><id>https://vidageek.com/2023/06/11/podcast-2x13</id><content type="html" xml:base="https://vidageek.com/2023/06/11/podcast-2x13.html"><![CDATA[<h1 id="la-visión-de-apple">La visión de Apple</h1>
<p>Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.</p>

<p>Y es que las nuevas gafas de Apple definen el futuro de la computación, o como ellos lo han llamado, la computación espacial. Un futuro en el que la pantalla no nos limitará en la interacción sino que podremos ampliarla o reducirla a nuestro antojo. O poner 3 pantallas si queremos.</p>

<p>Finalmente todas las especificaciones filtradas se cumplieron y tenemos unas gafas que tinen una pantalla superior a 4K en cada ojo con una densidad de píxeles superior a los 4000ppp, un procesador M2 junto a un coprocesador R1 que se encarga de la gestión de todos los sensores, que no son pocos. 12 cámaras, 6 micrófonos, seguimiento ocular y seguimiento de manos.</p>

<p>Estas gafas nos permiten crear un entorno virtual junto a nuestro entorno físico e interactuar con el mismo. Para ello no utilizamos controles externos sino que simplemente utilizamos nuestra vista y nuestras manos. Miramos lo que queremos seleccionar y pellizcamos con los dedos.</p>

<p>También tiene una corona digital con la cual controlaremos el nivel de inmersión en el sistema pudiendo ocultar por completo nuestro entorno real.</p>

<p>Además tiene una pantalla exterior en 3D que permite ver una recreación simulada de nuestros ojos de forma que da la sensación de que las gafas son transparentes.</p>

<p>La integración con el ecosistema es espectacular de forma que podemos “sacar” la pantalla de un Macbook y representarla en el espacio.</p>

<p>Lo malo es el precio, a partir de 3500$ más impuestos y sólo se pondrá a la venta en USA a partir del año que viene.</p>

<p>Tenemos muchas ganas de probarlas y veremos si somos capaces con hacernos con unas.</p>

<p>¡Un saludo y hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[La visión de Apple Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.]]></summary></entry><entry><title type="html">Podcast 2x12</title><link href="https://vidageek.com/2023/06/03/podcast-2x12.html" rel="alternate" type="text/html" title="Podcast 2x12" /><published>2023-06-03T00:00:00+00:00</published><updated>2023-06-03T00:00:00+00:00</updated><id>https://vidageek.com/2023/06/03/podcast-2x12</id><content type="html" xml:base="https://vidageek.com/2023/06/03/podcast-2x12.html"><![CDATA[<h1 id="según-esta-filtración-las-gafas-de-apple-tendían-unas-especificaciones-loquísimas">Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas</h1>
<p>Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:</p>

<ul>
  <li>Pantalla Micro-OLED de 1,41 pulgadas para cada ojo</li>
  <li>Resolución 4K en cada ojo</li>
  <li>Densidad de píxeles de 4000 ppi (puntos por pulgada)</li>
  <li>Más de 5000 nits de brillo</li>
  <li>ProMotion display hasta 120hz de refresco</li>
</ul>

<p>En comparación las PlayStation VR2 tienen unas pantallas de 2000x2400 pixeles (frente a 3840x2160 del 4K) y una densidad de píxeles de 850ppi…</p>

<p>Así se explica que hubiera otro rumor que situaba su precio en unos 3000$…</p>

<p>Fuente: <a href="https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter">https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter</a></p>

<h3 id="por-cierto-que-el-lunes-a-partir-de-las-1845-hora-española-daremos-cobertura-en-directo-al-evento-de-apple">Por cierto que el lunes a partir de las 18:45 hora española daremos cobertura en directo al evento de Apple.</h3>
<h2 id="suscríbete-a-nuestro-canal-de-youtube-para-verlo-en-directo-httpswwwyoutubecomliveskn2xcvt0lofeatureshareaa">Suscríbete a nuestro canal de YouTube para verlo en directo: <a href="https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share">https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share</a>aa</h2>

<hr />

<h1 id="imagebind-un-embedding-para-enlazarlos-a-todos">ImageBind un embedding para enlazarlos a todos</h1>
<p>Meta sigue dándonos muchas alegrías ya que ha presentado un nuevo modelo de IA que pretende enlazar múltiples y diversos fuentes de datos como:</p>
<ul>
  <li>Audio</li>
  <li>Texto</li>
  <li>Imagen</li>
  <li>Datos de profundidad</li>
  <li>Datos de aceleración</li>
  <li>Mapas de calor</li>
</ul>

<p>Este nuevo modelo multimodal crea unos embeddings que interrelacionan todos los datos aunque sean de diferente tipo. De este modo se le puede pasar un audio de un perro ladrando y encontrar imágenes de perros por ejemplo. Esto abre un nuevo campo en la IA ya que enlazándolo con los grandes modelos de lenguaje LLM nos permitrá una interacción multimodal tremenda.</p>

<p>Además, es de código abierto. Meta nos está sorprendiendo mucho en este campo y dejando atrás esa mala imagen que Facebook consiguió.</p>

<p><a href="https://imagebind.metademolab.com">https://imagebind.metademolab.com</a></p>

<hr />

<h1 id="mitigar-el-riesgo-de-extinción-humana-por-ia-debería-ser-una-prioridad-global">Mitigar el riesgo de extinción humana por IA debería ser una prioridad global</h1>
<p>Esto es lo que han dicho algunas figuras relevantes en el campo de la IA como los ganadores del premio Turing Geoffery Hinton y Yoshua Bengio así como el CEO de OpenAI Sam Altman, y otros ejecutivos de OpenAI como Ilya Sutskever y Mira Murati. Además también lo suscriben el CEO de DeepMind Demis Hassabis o el CEO de Anthropic Dario Amodei, y profesores de la UC Berkely, Stanford y MIT.</p>

<p>Esta vez no han escrito una <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">carta abierta</a> como sucedió en el pasado mes de marzo, sino que simplemente han dicho lo siguiente:</p>

<blockquote>
  <p><em>“Mitigar el riesgo de extinción por la IA debería ser una prioridad global junto con otros riesgos a escala social como las pandemias o las guerras nucleares.”</em></p>
</blockquote>

<p>Más información: <a href="https://www.safe.ai/press-release">https://www.safe.ai/press-release</a></p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:]]></summary></entry><entry><title type="html">Podcast 2x11</title><link href="https://vidageek.com/2023/05/27/podcast-2x11.html" rel="alternate" type="text/html" title="Podcast 2x11" /><published>2023-05-27T00:00:00+00:00</published><updated>2023-05-27T00:00:00+00:00</updated><id>https://vidageek.com/2023/05/27/podcast-2x11</id><content type="html" xml:base="https://vidageek.com/2023/05/27/podcast-2x11.html"><![CDATA[<h1 id="tree-of-thoughts-deliberate-problem-solving-with-large-language-models">Tree of thoughts: Deliberate problem solving with Large Language Models</h1>
<p><a href="https://arxiv.org/pdf/2305.10601.pdf">https://arxiv.org/pdf/2305.10601.pdf</a></p>

<p>Esta pasada semana se ha publicado un paper llamado “Tree of thoughts: Deliberate problem solving with Large Language Models” que sería algo como “Pensamiento arborescente: Solución de problemas con modelos grandes de lenguaje”. En este paper se explican los métodos más habituales en los que se usan los LLM como ChatGPT y se propone un nuevo método el cual mejora sustancialmente los métodos actuales.</p>

<p>Hasta ahora básicamente se usan 3 métodos:</p>
<ul>
  <li>Input-Output prompting: El cual consiste básicamente en hacer una pregunta para llegar a una respuesta. Sería lo que hacemos habitualmente con ChatGPT.</li>
  <li>Chain of thought prompting: Consiste en separar la pregunta en los pasos necesarios para llegar a una respuesta, de esta manera la respuesta siempre es más efectiva. Se utiliza en algunos proyectos como BabyAGI o AutoGPT.</li>
  <li>Self consistency with CoT: Que sería básicamente lo mismo que CoT pero haciendo la pregunta y elaborando los pasos varias veces de forma que nos quedaremos con la respuesta final que más se repita.</li>
</ul>

<p>Y el paper propone un nuevo método al que llama Tree of Thoughts o Árbol de pensamientos el cual consiste en, resumiéndolo mucho, en pedir al LLM que elabore varios planes para la resolución de un problema. Luego se le pide 5 veces que vote cuál es el mejor plan para resolver el problema planteado. Una vez hecho se le vuelve a pedir que elabore varios planes para resolver el problema basándose en los planes más votados y se vuelve a establecer un sistema de votaciones para esos planes generados. De esta manera se van creando unas ramas de pensamiento y las más votadas se van siguiendo. Es posible que alguna no llegue a buen puerto y se descarte esa rama por completo volviendo a una rama anterior.</p>

<p>Este nuevo método parece muy efectivo y es muy prometedor. En las pruebas que han realizado han conseguido unos resultados excelentes. Por ejemplo en la resolución de crucigramas, los métodos clásicos como IO o CoT solo conseguían resolver 1 de cada 100 en el mejor de los casos mientras que ToT ha conseguido resolver 20 de cada 100. E incluso es más impresionante en el juego de 24 en el cual los métodos tradicionales conseguían un 9% de éxito mientras que ToT consigue un 74% de soluciones correctas.</p>

<p>Ya ha salido una implementación en Python para que se pueda probar y trastear con ello:
<a href="https://github.com/kyegomez/tree-of-thoughts">https://github.com/kyegomez/tree-of-thoughts</a></p>

<h1 id="drag-your-gan-interactive-point-based-manipulation-on-the-generative-image-manifold">Drag your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</h1>
<p><a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/">https://vcai.mpi-inf.mpg.de/projects/DragGAN/</a></p>

<p>Este paper que se podría traducir como “Arrastra tu GAN, Manipulación interactiva basada en puntos de la variedad de imágenes generativas</p>

<hr />

<h1 id="mandos-de-videojuego-accesibles">Mandos de videojuego accesibles</h1>
<p>Hoy os traemos unos cuantos mandos económicos para poder disfrutar de nuestros juegos sin que nos escueza el bolsillo.</p>

<p>En concreto son estos modelos:
    - <a href="https://amzn.to/3C0N0mo">Microsoft Xbox original (XBOX y PC)</a>
    - <a href="https://amzn.to/3BVTR0l">Nacon - Compact Mando (PS4 y PC)</a>
    - <a href="https://amzn.to/3qiIvk9">G-Lab K-Pad Thorium Mando Gaming (PS3 y PC)</a>
    - <a href="https://amzn.to/3OGUySy">Diswoe Mando Xbox 360 (PC)</a>
    - <a href="https://amzn.to/3BXoYIT">PowerA (Xbox Series X|S Y PC)</a></p>

<h2 id="recomendacion">Recomendacion</h2>
<p>Desde mi punto de vista eligiria de todos ellos el mando POWER A por su calidad de acabado, precio y ergonomia a la hora de jugar ya que es practicamente lo mismo que el de xbox original pero con cable. Eso lo hace mas ligero pero con el incoveniente de tenerlo que tener conectado por cable.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tree of thoughts: Deliberate problem solving with Large Language Models https://arxiv.org/pdf/2305.10601.pdf]]></summary></entry><entry><title type="html">Podcast 2x10</title><link href="https://vidageek.com/2023/05/20/podcast-2x10.html" rel="alternate" type="text/html" title="Podcast 2x10" /><published>2023-05-20T00:00:00+00:00</published><updated>2023-05-20T00:00:00+00:00</updated><id>https://vidageek.com/2023/05/20/podcast-2x10</id><content type="html" xml:base="https://vidageek.com/2023/05/20/podcast-2x10.html"><![CDATA[<h1 id="habla-con-tus-documentos">Habla con tus documentos</h1>
<p>Esta semana os explicamos cómo hablar con vuestros documentos. Para ello hacemos uso de diferentes herramientas como <a href="https://www.chatpdf.com?via=vidageek">ChatPDF</a> o <a href="https://github.com/imartinez/privateGPT">PrivateGPT</a>.</p>

<p>El modo como funcionan estas herramientas se divide en 3 partes:</p>

<ul>
  <li>
    <p>Extracción de texto
El primer paso es extraer todo el texto del documento y categorizarlo con metadatos como número de página, autor, etc.</p>
  </li>
  <li>
    <p>Extraer embeddings del texto
Este paso utiliza un modelo que analiza semánticamente el texto y lo convierte a vectores de forma que puede ser indexado en una base de datos vectorial como <a href="https://pinecone.io">Pinecone</a> o similar.</p>
  </li>
  <li>
    <p>“Conversar” con el documento
Este último paso realiza el paso anterior por cada consulta que le realicemos. Es decir, genera embeddings de la consulta que queremos hacer para luego poder hacer una búsqueda en la base de datos de forma que encontrará los textos que se acerquen más de forma semántica a la consulta para utilizarlos como contexto o referencia en la consulta final.</p>
  </li>
</ul>

<h2 id="chatpdf">ChatPDF</h2>
<p><a href="https://www.chatpdf.com?via=vidageek">ChatPDF</a> es una herramienta online que utiliza por detrás los modelos de lenguaje de <a href="https://openai.com">OpenAI</a> como ChatGPT para las consultas o ADA para los embeddings. Es un servicio gratuito con limitaciones de hasta 120 páginas por documento o 3 documentos por día. Es muy sencilla de utilizar pero como inconveniente tiene que todo es procesdo online de forma que, si trabajamos con documentos sensibles o confidenciales, no deberíamos utilizarla.</p>

<h2 id="privategpt">PrivateGPT</h2>
<p>Por el contrario el proyecto <a href="https://github.com/imartinez/privateGPT">PrivateGPT</a> utiliza un modelo de lenguaje de código abierto que se ejecuta en local, directamente en tu CPU. Esto tiene la gran ventaja de que podemos trabajar con documentos confidenciales pero como contrapartida es mucho más lento, dependiendo en gran medida de la potencia de la CPU.</p>

<p>Como ejemplo os hemos puesto un <a href="https://colab.research.google.com/drive/1ikKWtOx73NirUjf72mNHJt_Q9uKI7m61#scrollTo=rV2Ydj-tqX-P">Google Colab</a> para que podáis probarlo aunque os adelantamos que es especialmente lento al usar sólo la CPU…</p>

<hr />
<h1 id="amazfit-gtr-4-y-gts-4">Amazfit GTR 4 y GTS 4</h1>

<h2 id="acerca-de-estos-relojes">Acerca de estos relojes</h2>
<p>Dos relojes muy similares por dentro pero muy diferentes por fuera.
El <a href="https://amzn.to/3WmkgO4">Amazfit GTR 4</a> cuenta con una pantalla HD amoled de 1.43 pulgadas con una resolucion de 466x466 Pixeles. Cuenta además con una batería que prometen durar unos 15 días. Con sensores para deporte con 150 modos de entrenamiento, control del sueño etc. Una opcion muy buena para el dia a dia y con un tamaño y forma muy deportivo</p>

<p>Por otro lado, el <a href="https://amzn.to/3pWDVbs">Amazfit GTS 4</a>, al contrario que su hermano, es rectangular(el gtr es redondo) y es la mayor diferencia que podemos encontrar en el dado que sus sensores son iguales. El peso tambien al ser mas pequeño es menor, la bateria pasa lo mismo pero no por ello malo ni mucho menos.</p>

<p>Cuenta con una pantalla de 1.75 pulgadas, comentamos en directo que la pantalla del gtr 4 era mas grande pero como dicen los datos lo dijimos mal.</p>

<p>En ambos casos hay que usar la aplicacion de Amazfit para poder usar las funcionalidades del mismo con nuestro telefono movil.
Dos opciones de relojes muy recomentadables y mucho mas asequible que otras marcas y desde luego para el dia a dia no dudaria en comprarmelo</p>

<h2 id="ventajas">Ventajas</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Bateria
- Pantalla
- Precio
</code></pre></div></div>

<h2 id="desventajas">Desventajas</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- No cuenta con NFC
- Fácil de rallar
- Aplicacion de terceros 
</code></pre></div></div>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Habla con tus documentos Esta semana os explicamos cómo hablar con vuestros documentos. Para ello hacemos uso de diferentes herramientas como ChatPDF o PrivateGPT.]]></summary></entry><entry><title type="html">Podcast 2x09</title><link href="https://vidageek.com/2023/05/13/podcast-2x09.html" rel="alternate" type="text/html" title="Podcast 2x09" /><published>2023-05-13T00:00:00+00:00</published><updated>2023-05-13T00:00:00+00:00</updated><id>https://vidageek.com/2023/05/13/podcast-2x09</id><content type="html" xml:base="https://vidageek.com/2023/05/13/podcast-2x09.html"><![CDATA[<h1 id="cómo-esconder-mensajes-secretos-a-plena-vista">Cómo esconder mensajes secretos a plena vista</h1>
<p>Esta semana os vamos a hablar de la esteganografía, el arte de esconder mensajes a plena vista. Imagina que quieres enviar un mensaje secreto a tu mejor amigo, pero no quieres que tus hermanos o compañeros de clase lo lean. Entonces, en lugar de escribir el mensaje en un papel y ponerlo en un sobre, decides esconderlo dentro de un dibujo o una foto para que nadie sospeche que hay algo más. Eso es la esteganografía: esconder un mensaje dentro de otra cosa para que nadie se dé cuenta de que está ahí.</p>

<h2 id="etimología">Etimología</h2>
<p>La palabra “esteganografía” proviene de dos palabras griegas: “steganos” (στεγανός) y “graphein” (γράφειν). “Steganos” significa “cubierto” o “escondido”, mientras que “graphein” significa “escribir” o “dibujar”. Por lo tanto, la etimología de “esteganografía” se traduce aproximadamente como “escritura escondida” o “escritura encubierta”, lo que refleja la idea de ocultar mensajes secretos dentro de otros medios, como imágenes, textos o archivos de audio.</p>

<h2 id="tipos-de-esteganografía">Tipos de esteganografía</h2>
<p>Hay diferentes tipos de esteganografía, dependiendo de en qué escondes el mensaje:</p>

<ul>
  <li>
    <p>Esteganografía en imágenes: Escondes el mensaje dentro de una foto o un dibujo, cambiando un poquito los colores o los detalles de la imagen.</p>
  </li>
  <li>
    <p>Esteganografía en audio: Puedes esconder el mensaje dentro de una grabación de música o sonido, cambiando un poquito las ondas de sonido.</p>
  </li>
  <li>
    <p>Esteganografía en texto: Aquí, escondes el mensaje dentro de un texto, utilizando letras o palabras extrañas, o cambiando el tamaño y el color de las letras.</p>
  </li>
  <li>
    <p>Esteganografía en redes: En este caso, escondes el mensaje en la forma en que se envían los datos por internet u otras redes, para que no se pueda saber qué información se está compartiendo.</p>
  </li>
</ul>

<h2 id="historia">Historia</h2>
<p>La esteganografía se ha utilizado desde hace mucho tiempo. La primera vez que se tiene constancia de su uso fue en la antigua Grecia, alrededor del año 440 a.C. Un famoso general griego llamado Histiaeus quería enviar un mensaje secreto a uno de sus aliados. Entonces, afeitó la cabeza de uno de sus mensajeros, escribió el mensaje en su cuero cabelludo y esperó a que el cabello volviera a crecer. Cuando el cabello del mensajero creció lo suficiente para cubrir el mensaje, lo envió a entregar el mensaje secreto. Al llegar a su destino, el aliado volvió a afeitar la cabeza del mensajero y pudo leer el mensaje oculto.</p>

<h2 id="tutorial-esconde-un-mensaje-en-una-imagen-jpeg">Tutorial: esconde un mensaje en una imagen JPEG</h2>
<p>Para este tutorial vamos a hacer uso de un cuaderno que hemos creado de una forma sencilla.</p>

<ul>
  <li>Ocultar mensaje: <a href="https://colab.research.google.com/drive/1B5oYFHjQQZ7DJckB9HLm6U4GmKEFo0fn">Esteganografía en JPG ocultar mensaje</a></li>
  <li>Revelar mensaje: <a href="https://colab.research.google.com/drive/180wShYdVHgPU8WPBfxrWAkJnYpglSOr_">Esteganografía en JPG revelar mensaje</a></li>
</ul>

<hr />
<h1 id="legion-pro-7i-gen-8-el-ordenador-ideal-para-gamers-exigentes">Legion Pro 7i Gen 8: El ordenador ideal para gamers exigentes</h1>

<p>El <a href="https://amzn.to/3MnkXTP">Legion Pro 7i Gen 8</a> es un ordenador diseñado específicamente para disfrutar de tus videojuegos favoritos. Con una pantalla de excelente calidad y una tarjeta gráfica de última generación, podrás jugar a cualquier juego con una calidad altísima. La única desventaja es su batería, que puede durar menos de una hora, por lo que es recomendable tenerlo siempre conectado a la corriente para que la GPU funcione a pleno rendimiento. Además, cuenta con un teclado retroiluminado RGB que permite multitud de combinaciones. En definitiva, una elección TOP para juegos que durará muchos años gracias a sus 32 GB de RAM, 1 TB de disco SSD y 12 GB de gráfica RTX 4070. Debido a que está pensado para rendimiento, su tamaño y peso son amplios para garantizar una buena refrigeración y evitar que los componentes sufran en exceso. Sin duda, Lenovo está haciendo un trabajo estupendo con esta gama Legion.</p>

<h2 id="ventajas">Ventajas</h2>
<ul>
  <li>Pantalla de 16” a 240 Hz que ofrece una experiencia de juego incomparable.</li>
  <li>Tarjeta gráfica de última generación RTX 4070 de 12 GB que permite jugar a cualquier juego con una calidad altísima.</li>
  <li>Procesador Intel i9 para una mayor rapidez y eficiencia.</li>
</ul>

<h2 id="desventajas">Desventajas</h2>
<ul>
  <li>Batería de poca duración, por lo que es recomendable tenerlo conectado a la corriente para poder jugar sin problemas.</li>
  <li>Tamaño y peso elevados debido a su diseño enfocado en la refrigeración.</li>
  <li>Precio elevado, aunque su calidad lo convierte en una inversión a largo plazo para los gamers más exigentes.</li>
</ul>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Cómo esconder mensajes secretos a plena vista Esta semana os vamos a hablar de la esteganografía, el arte de esconder mensajes a plena vista. Imagina que quieres enviar un mensaje secreto a tu mejor amigo, pero no quieres que tus hermanos o compañeros de clase lo lean. Entonces, en lugar de escribir el mensaje en un papel y ponerlo en un sobre, decides esconderlo dentro de un dibujo o una foto para que nadie sospeche que hay algo más. Eso es la esteganografía: esconder un mensaje dentro de otra cosa para que nadie se dé cuenta de que está ahí.]]></summary></entry><entry><title type="html">Podcast 2x08</title><link href="https://vidageek.com/2023/05/06/podcast-2x08.html" rel="alternate" type="text/html" title="Podcast 2x08" /><published>2023-05-06T00:00:00+00:00</published><updated>2023-05-06T00:00:00+00:00</updated><id>https://vidageek.com/2023/05/06/podcast-2x08</id><content type="html" xml:base="https://vidageek.com/2023/05/06/podcast-2x08.html"><![CDATA[<h1 id="cómo-generar-imágenes-geniales-con-ia">Cómo generar imágenes geniales con IA</h1>
<p>Si ya hemos visto cómo generar audio con IA y cómo hablar con un modelo de lenguaje, esta semana os traemos cómo generar imágenes con IA. Hablaremos de <a href="https://openai.com/research/dall-e">Dall-E</a>, una herramienta de <a href="https://openai.com">OpenAI</a> y una de las primeras en la generación de imágenes. También probaremos <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">Stable Difussion</a> y <a href="https://www.bluewillow.ai">BlueWillow</a> para comparar cómo generan imágenes cada una de ellas.</p>

<p>Después hablamos sobre un nuevo proyecto de código abierto que ha irrumpido en escena llamado <a href="https://github.com/deep-floyd/IF">IF de DeepFloyd</a> el cual ha sido el primero en ser capaz de generar imágenes en las cuales podemos pedir que añada un texto y éste aparecerá en la imagen de forma correcta. Hasta ahora las imágenes generadas en otras herramientas eran incapaces de generar el texto de forma coherente.</p>

<h2 id="star-wars-jedi-survivor">Star Wars Jedi: Survivor</h2>
<p>Os traemos un nuevo juego de acción y aventuras en tercera persona desarrollado por Respawn Entertainment y publicado por Electronic Arts. El juego se lanzó el 26 de abril de 2023 para PlayStation 5, Xbox Series X/S y PC. El juego sigue la historia de Cal Kestis, un joven Padawan Jedi que sobrevivió a la Orden 66 y ahora vive como un fugitivo en la galaxia. El juego ha recibido críticas positivas por su jugabilidad, historia y gráficos. IGN le dio al juego una puntuación de 9/10, mientras que PC Gamer le dio una puntuación de 8/10. The Guardian le dio al juego una puntuación perfecta de 5 estrellas. Sin embargo, el juego también ha sido criticado por sus problemas técnicos y problemas de velocidad de fotogramas.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Cómo generar imágenes geniales con IA Si ya hemos visto cómo generar audio con IA y cómo hablar con un modelo de lenguaje, esta semana os traemos cómo generar imágenes con IA. Hablaremos de Dall-E, una herramienta de OpenAI y una de las primeras en la generación de imágenes. También probaremos Stable Difussion y BlueWillow para comparar cómo generan imágenes cada una de ellas.]]></summary></entry><entry><title type="html">Podcast 2x07</title><link href="https://vidageek.com/2023/04/29/podcast-2x07.html" rel="alternate" type="text/html" title="Podcast 2x07" /><published>2023-04-29T00:00:00+00:00</published><updated>2023-04-29T00:00:00+00:00</updated><id>https://vidageek.com/2023/04/29/podcast-2x07</id><content type="html" xml:base="https://vidageek.com/2023/04/29/podcast-2x07.html"><![CDATA[<h1 id="olvídate-del-backend-con-appwrite">Olvídate del backend con AppWrite</h1>
<p>Hoy hablamos sobre <a href="[https://appwrite.io]">AppWrite</a>, un proyecto de código abierto para crear tu backend de una forma fácil y rápida. Puedes instalar <a href="[https://appwrite.io]">AppWrite</a> en tu servidor utilizando docker o directamente utilizando AppWrite Cloud y de esta forma no tener que preocuparte de absolutamente nada.</p>

<p>Puedes integrar AppWrite con cualquier plataforma con sus SDKs para cualquier lenguaje de programación o framework como Flutter, iOS, Android, JS, etc.</p>

<h2 id="unrecord-videojuego-con-unreal-engine-5">Unrecord Videojuego con Unreal Engine 5</h2>
<p>Unrecord será uno de los primeros juegos en utilizar el nuevo motor de imagen Unreal Engine 5. Promete ser mucho mas realista (cosa que veremos) y mucho más espectacular en cuanto a imagen. Nos pondremos en la piel de un policía visto desde la camara que llevan en el hombro como si de una gopro se tratara. Sin duda una vista algo inusual para un juego de disparos pero que desde luego le da una sensación de realismo brutal.</p>

<p>Actualmente está en desarrollo y en principio solo saldrá para PC. Podéis seguirlo en <a href="https://store.steampowered.com/app/2381520/Unrecord/">Steam</a> o en su <a href="https://discord.com/invite/3xFRSXuDgDfork">Discord</a>. Además podéis ver un <a href="https://www.youtube.com/watch?v=IK76q13Aqt0">vídeo de demostración en YouTube</a>.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Olvídate del backend con AppWrite Hoy hablamos sobre AppWrite, un proyecto de código abierto para crear tu backend de una forma fácil y rápida. Puedes instalar AppWrite en tu servidor utilizando docker o directamente utilizando AppWrite Cloud y de esta forma no tener que preocuparte de absolutamente nada.]]></summary></entry><entry><title type="html">Podcast 2x06</title><link href="https://vidageek.com/2023/04/22/podcast-2x06.html" rel="alternate" type="text/html" title="Podcast 2x06" /><published>2023-04-22T00:00:00+00:00</published><updated>2023-04-22T00:00:00+00:00</updated><id>https://vidageek.com/2023/04/22/podcast-2x06</id><content type="html" xml:base="https://vidageek.com/2023/04/22/podcast-2x06.html"><![CDATA[<h1 id="clona-tu-propia-voz-o-la-de-tu-vecino">Clona tu propia voz… o la de tu vecino</h1>
<p>La inteligencia artificial no para. La semana pasada hablábamos de cómo <a href="https://open.spotify.com/artist/1si6mnxJ6IpTOTW13ECa0o">Alltta</a> había creado una canción utilizando por inteligencia artificial con la voz de Jay-Z y esta semana os traemos un proyecto de código abierto llamado <a href="https://github.com/voicepaw/so-vits-svc-fork">SoftVC VITS</a> con el que podrás hacerlo tú mismo. Este proyecto en concreto es un fork del proyecto original el cual nos permite hacer incluso inferencia en tiempo real. Además alguien ha creado unos cuantos modelos de voces que podemos <a href="https://huggingface.co/marcoc2/so-vits-svc-4.0-models">descargar libremente</a> con voces como la de Lady Gaga, Billie Joe o David Bowie.</p>

<hr />
<blockquote>
  <h3 id="patrocinado-por-qoodiht-tus-fundas-sostenibles">Patrocinado por Qoodiht, tus fundas sostenibles</h3>
  <p>El episodio de hoy está patrocinado por <a href="https://qoodiht.myshopify.com">Qoodiht</a>, unas nuevas fundas ecológicas para tu iPhone, fabricadas en España con un material ecológico y sostenible. Llevo un par de semanas utilizando la funda modelo GEA y estoy gratamente sorprendido. Tan sólo cuestan 7,95€ y están disponibles en color blanco y verde fluor. Además tienen una funda, el modelo Apolo, que brilla en la oscuridad.</p>
</blockquote>

<hr />

<h2 id="puedo-clonar-la-voz-de-cualquier-persona-qué-dice-la-ley-al-respecto">¿Puedo clonar la voz de cualquier persona? ¿Qué dice la ley al respecto?</h2>
<p>Hablamos con Javier Maestre, un abogado experto en nuevas tecnologías que nos cuenta qué dice la ley al respecto de utilizar la voz creada por la IA.</p>

<h2 id="qué-son-las-gan-o-redes-generativas-adversarias">¿Qué son las GAN o Redes Generativas Adversarias?</h2>
<p>Una GAN (Generative Adversarial Network o red generativa antagónica en Español) fue creada por Ian Goodfellow en 2017. Son un tipo de inteligencia artificial que se utiliza para crear cosas nuevas, como imágenes o sonidos, imitando ejemplos existentes. Imagina que es como un artista y un crítico que trabajan juntos: el artista crea una obra y el crítico la evalúa. En una GAN, hay dos partes: el generador, que es como el artista, y el discriminador, que es como el crítico. El generador crea imágenes (u otros tipos de datos) y el discriminador evalúa si son reales (parecidas a los ejemplos existentes) o falsas (hechas por el generador). Ambos van aprendiendo y mejorando en su trabajo a medida que se entrenan, lo que hace que la GAN sea cada vez más efectiva para crear cosas que parezcan reales.
Se utilizaron para deepfakes</p>

<h2 id="para-la-música-o-la-voz">Para la música… o la voz</h2>
<p>Lo más interesante de este proyecto es que, si bien está pensado para cambiar la voz en canciones, se puede utilizar de la misma manera para el habla, de forma que tu voz sea cambiada por ejemplo… por la de tu jefe, o por la de tu vecino. Yo mismo he creado un modelo de la voz de Paco en apenas unas horas y con un coste de… 0€. Totalmente gratuito utilizando la plataforma de Google Colab.</p>

<h2 id="cómo-clonar-tu-voz">Cómo clonar tu voz</h2>
<p>Para poder realizar el modelo de una voz es necesario tener unos cuantos minutos de la voz que queremos clonar de forma clara. Si por ejemplo queremos clonar nuestra propia voz, es suficiente con grabarnos hablar durante unos 10 o 15 minutos. Si queremos clonar una voz de una canción será necesario eliminar la música de fondo  antes de utilizarla.</p>

<p>Una vez obtenida la voz es necesario trocearla en diferentes samples de unos 10 segundos o menos de duración. En mi caso he utilizado mi voz del último podcast y la he troceado de forma automática utilizando un script en python que automáticamente busca los silencios y lo separa.</p>

<p>Después no tiene mayor misterio más que seguir <a href="https://vidageek.com/entrenarvoz">este cuaderno</a> que os hemos creado para que, en unos sencillos pasos, podamos crear nuestro propio modelo de voz. Una vez generado podemos utilizar <a href="https://colab.research.google.com/github/34j/so-vits-svc-fork/blob/main/notebooks/so-vits-svc-fork-4.0.ipynb">este otro</a> para cambiar nuestra voz por la de nuestro modelo.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Clona tu propia voz… o la de tu vecino La inteligencia artificial no para. La semana pasada hablábamos de cómo Alltta había creado una canción utilizando por inteligencia artificial con la voz de Jay-Z y esta semana os traemos un proyecto de código abierto llamado SoftVC VITS con el que podrás hacerlo tú mismo. Este proyecto en concreto es un fork del proyecto original el cual nos permite hacer incluso inferencia en tiempo real. Además alguien ha creado unos cuantos modelos de voces que podemos descargar libremente con voces como la de Lady Gaga, Billie Joe o David Bowie.]]></summary></entry><entry><title type="html">Podcast 16</title><link href="https://vidageek.com/2023/04/14/podcast-16.html" rel="alternate" type="text/html" title="Podcast 16" /><published>2023-04-14T00:00:00+00:00</published><updated>2023-04-14T00:00:00+00:00</updated><id>https://vidageek.com/2023/04/14/podcast-16</id><content type="html" xml:base="https://vidageek.com/2023/04/14/podcast-16.html"><![CDATA[<h1 id="alltta-y-cómo-jay-z-no-colabora-en-su-último-tema-savages">Alltta y cómo Jay-Z no colabora en su último tema “Savages”</h1>
<p>Hoy seguimos con inteligencia artificial pero esta vez dedicada al audio. Hace unos días el grupo de rap <a href="https://open.spotify.com/artist/1si6mnxJ6IpTOTW13ECa0o">Alltta</a> ha publicado <a href="https://www.youtube.com/watch?v=y7r6PAkFRfU">Savages</a>, un tema en el que aparece Jay-Z colaborando… solo que no es Jay-Z el que canta y tampoco un ser humano…</p>

<p>Comenatamos cómo es posible clonar tu voz con herramientas como <a href="https://www.descript.com/overdub">Overdub</a>, <a href="https://fakeyou.com">FakeYou</a> o <a href="https://huggingface.co/spaces/coqui/CoquiTTS">Coqui</a> entre otras.</p>

<h1 id="xiaomi-compresor-de-aire-eléctrico-portátil-1s">Xiaomi Compresor de aire eléctrico portátil 1S</h1>
<p>El <a href="https://amzn.to/3UH4tc0">Xiaomi Portable Electric Air Compressor 1S</a> es un compresor de aire eléctrico portátil que se puede utilizar para inflar neumáticos, pelotas u otros objetos inflables de manera rápida y sencilla</p>

<h2 id="caracteristicas">Caracteristicas</h2>

<p>Tiene una precisión de ±2 psi y una capacidad de batería de 2.000mAh (14,8Wh) que puede durar unos 18 minutos con una carga completa. También tiene un diseño compacto y se puede transportar fácilmente a cualquier lugar. El <a href="https://amzn.to/3UH4tc0">Xiaomi Portable Electric Air Compressor 1S</a> tiene un motor más potente que el Xiaomi Portable Electric Air Compressor lo que le permite llenar el aire del neumático a un ritmo más rápido2. También tiene un puerto de carga USB Tipo-C en comparación con el puerto microUSB del modelo anterior2. Según un análisis realizado por Xataka, el Xiaomi Electric Air Compressor 1S tardó 13 minutos y 20 segundos en llenar un neumático 215/60/R16 completamente desinflado a 34 PSI</p>

<h2 id="ventajas">Ventajas</h2>
<ul>
  <li>Portatil</li>
  <li>Duracion de la bateria</li>
  <li>Tamaño</li>
</ul>

<h2 id="conclusión">Conclusión</h2>
<p>Un dispositivo que me ha resultado muy util y que no hay excusa para tener las ruedas bajas de presion. Muy recomendable dado que su tamaño es muy reducido y un uso muy sencillo. Viene acompañado de utiles para inflar balones de fútbol y es compatible con la mayoria de las válvulas que hay en el mercado.</p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Alltta y cómo Jay-Z no colabora en su último tema “Savages” Hoy seguimos con inteligencia artificial pero esta vez dedicada al audio. Hace unos días el grupo de rap Alltta ha publicado Savages, un tema en el que aparece Jay-Z colaborando… solo que no es Jay-Z el que canta y tampoco un ser humano…]]></summary></entry></feed>