<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://vidageek.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://vidageek.com/" rel="alternate" type="text/html" /><updated>2024-01-09T13:27:30+00:00</updated><id>https://vidageek.com/feed.xml</id><title type="html">VidaGeek</title><subtitle>Un podcast sobre tecnología, programación, videojuegos y mucho más</subtitle><entry><title type="html">Podcast 3x07</title><link href="https://vidageek.com/3/2024/01/09/podcast-3x07.html" rel="alternate" type="text/html" title="Podcast 3x07" /><published>2024-01-09T00:00:00+00:00</published><updated>2024-01-09T00:00:00+00:00</updated><id>https://vidageek.com/3/2024/01/09/podcast-3x07</id><content type="html" xml:base="https://vidageek.com/3/2024/01/09/podcast-3x07.html"><![CDATA[<h1 id="microsoft-lo-apuesta-todo-a-la-ia---ios-173-protegerá-aún-más-nuestros-iphone---xiaomi-lanzará-un-coche-eléctrico">Microsoft lo apuesta todo a la IA - iOS 17.3 protegerá aún más nuestros iPhone - Xiaomi lanzará un coche eléctrico</h1>

<p>En este episodio os contamos cómo Microsoft lo apuesta todo a la IA <a href="https://www.genbeta.com/actualidad/nuestros-teclados-cambiaran-30-anos-despues-nueva-tecla-ia-microsoft-al-alcance-nuestros-dedos">lanzando un nuevo teclado</a> con un nuevo botón destinado a Copilot. También hablamos de la próxima actualización de iOS la cual <a href="https://blogthinkbig.com/ios-17-3-estrena-stolen-device-protection-que-es-y-por-que-debes-activarlo">añade una nueva funcionalidad para proteger nuestros dispositivos</a>.</p>

<p>Además os contamos sobre el <a href="https://www.xataka.com/movilidad/xiaomi-su7-coche-electrico-apunta-directamente-a-tesla-porsche-presumiendo-rendimiento-conduccion-autonoma">futuro coche eléctrico de Xiaomi</a>, el cual dará mucho que hablar.</p>

<p>¡Que lo disfrutéis!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Microsoft lo apuesta todo a la IA - iOS 17.3 protegerá aún más nuestros iPhone - Xiaomi lanzará un coche eléctrico]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://vidageek.com/media/VidaGeek_3x07-cover.jpg" /><media:content medium="image" url="https://vidageek.com/media/VidaGeek_3x07-cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Podcast 3x06</title><link href="https://vidageek.com/3/2023/12/13/podcast-3x06.html" rel="alternate" type="text/html" title="Podcast 3x06" /><published>2023-12-13T00:00:00+00:00</published><updated>2023-12-13T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/12/13/podcast-3x06</id><content type="html" xml:base="https://vidageek.com/3/2023/12/13/podcast-3x06.html"><![CDATA[<h1 id="nos-engaña-google-con-su-nueva-ia">¿Nos engaña Google con su nueva IA?</h1>

<p>En este episodio os contamos la polémica con la presentación del nuevo <a href="https://www.youtube.com/watch?v=UIZAiXYceBI&amp;t=86s">proyecto Gemini de Google</a> ya que parece ser que lo que han presentado <a href="https://www.lavanguardia.com/andro4all/google/acusan-a-google-de-falsear-el-video-de-demostracion-de-gemini-su-nuevo-modelo-de-ia">no es exactamente lo que realmente puede hacer su modelo de IA</a>.</p>

<p>Además os hablamos sobre el <a href="https://www.apple.com/es/shop/buy-watch/apple-watch-ultra/explorar">Apple Watch Ultra 2</a>, al cual finalmente Paco no se ha podido resistir, y sobre <a href="https://www.youtube.com/watch?v=QdBZY2fkU-0">GTA VI</a> entre otras cosas.</p>

<p>¡Que lo disfrutéis!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[¿Nos engaña Google con su nueva IA?]]></summary></entry><entry><title type="html">Podcast 3x05</title><link href="https://vidageek.com/3/2023/12/01/podcast-3x05.html" rel="alternate" type="text/html" title="Podcast 3x05" /><published>2023-12-01T00:00:00+00:00</published><updated>2023-12-01T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/12/01/podcast-3x05</id><content type="html" xml:base="https://vidageek.com/3/2023/12/01/podcast-3x05.html"><![CDATA[<h1 id="openhaystack-airtags-para-todos">OpenHaystack, AirTags para todos</h1>
<p>Hoy os hablamos sobre OpenHaystack, un proyecto de código abierto realizado por la universidad <a href="https://www.tu-darmstadt.de">TU Darmstadt</a> a partir de ingenieria inversa del protocolo de los AirTag. Nos permite poder crear nuestros propios AirTags y que funcionen dentro de la red FindMy de Apple. Además, jugando con el proyecto, he realizado un nuevo firmware de muy bajo consumo que funciona con los chips nrf52 de Nordic.</p>

<p>Aquí os dejo los enlaces del proyecto y del firmware de bajo consumo:</p>
<ul>
  <li>Proyecto OpenHaystack: <a href="https://github.com/seemoo-lab/openhaystack">https://github.com/seemoo-lab/openhaystack</a></li>
  <li>Firmware modificado de muy bajo consumo: <a href="https://github.com/acalatrava/openhaystack-firmware">https://github.com/acalatrava/openhaystack-firmware</a></li>
  <li>Firmware más avanzado que permite incluso actualización DFU: <a href="https://github.com/spaceinvadertech/openhaystack_moko">https://github.com/spaceinvadertech/openhaystack_moko</a></li>
</ul>

<p>Y aquí podéis encontrar un “clon” chino compatible con la red FindMy de Apple de forma oficial que cuestan apenas 5€:</p>
<ul>
  <li><a href="https://www.aliexpress.us/item/1005005978714839.html">Aiyato Global Tracker</a></li>
</ul>

<p>¡Un saludo!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[OpenHaystack, AirTags para todos Hoy os hablamos sobre OpenHaystack, un proyecto de código abierto realizado por la universidad TU Darmstadt a partir de ingenieria inversa del protocolo de los AirTag. Nos permite poder crear nuestros propios AirTags y que funcionen dentro de la red FindMy de Apple. Además, jugando con el proyecto, he realizado un nuevo firmware de muy bajo consumo que funciona con los chips nrf52 de Nordic.]]></summary></entry><entry><title type="html">Podcast 3x04</title><link href="https://vidageek.com/3/2023/11/19/podcast-3x04.html" rel="alternate" type="text/html" title="Podcast 3x04" /><published>2023-11-19T00:00:00+00:00</published><updated>2023-11-19T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/11/19/podcast-3x04</id><content type="html" xml:base="https://vidageek.com/3/2023/11/19/podcast-3x04.html"><![CDATA[<h1 id="sam-altman-es-despedido-y-readmitido">Sam Altman es despedido… ¿y readmitido?</h1>
<p>Este fin de semana OpenAI se ha levantado de resaca. El viernes a mediodía despedían a Sam Altman sin previo aviso… ¿pero parece ser que apenas 48 horas más tarde se han arrepentido?</p>

<h1 id="el-nuevo-dispositivo-ai-pin-quiere-ser-lo-que-le-siga-al-smartphone">El nuevo dispositivo AI Pin quiere ser lo que le siga al smartphone</h1>
<p>Humane ha presentado su nuevo AI Pin, un dispositivo móvil que no se parece a nada de lo que hayas visto antes… para bien y para mal. Está cargado de inteligencia artificial y pretende remplazar de alguna forma al smartphone.</p>

<h1 id="elon-musk-consigue-un-nuevo-hito-en-el-lanzamiento-de-starship">Elon Musk consigue un nuevo hito en el lanzamiento de Starship</h1>
<p>El último lanzamiento de Starship ha sido un éxito consiguiendo nuevos hitos. El avance de la misión va estupendamente.</p>

<p>Te lo contamos todo en este nuevo episodio, ¡Que lo disfrutes!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Sam Altman es despedido… ¿y readmitido? Este fin de semana OpenAI se ha levantado de resaca. El viernes a mediodía despedían a Sam Altman sin previo aviso… ¿pero parece ser que apenas 48 horas más tarde se han arrepentido?]]></summary></entry><entry><title type="html">Podcast 3x03</title><link href="https://vidageek.com/3/2023/11/05/podcast-3x03.html" rel="alternate" type="text/html" title="Podcast 3x03" /><published>2023-11-05T00:00:00+00:00</published><updated>2023-11-05T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/11/05/podcast-3x03</id><content type="html" xml:base="https://vidageek.com/3/2023/11/05/podcast-3x03.html"><![CDATA[<h1 id="copias-de-seguridad">Copias de seguridad</h1>
<p>En el episodio de hoy hablamos sobre copias de seguridad y sobre cómo confiar sólo en la nube, ya sea iCloud o cualquier otra, no es una buena idea. Descubriremos por qué la búsqueda de un sistema de backup le ha llevado a Antonio a suscribirse a una plataforma de videojuegos y explicamos cómo utilizar el servicio <a href="https://backblaze.com">Backblaze</a> para realizar copias de seguridad de nuestro equipo.</p>

<p>También comentamos cómo Antonio ha utilizado una herramienta de código abierto llamada <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader">iCloud Photo Downloader</a> para descargar toda su librería de fotos de iCloud a un disco duro local.</p>

<hr />
<p>¡Que lo disfrutes!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Copias de seguridad En el episodio de hoy hablamos sobre copias de seguridad y sobre cómo confiar sólo en la nube, ya sea iCloud o cualquier otra, no es una buena idea. Descubriremos por qué la búsqueda de un sistema de backup le ha llevado a Antonio a suscribirse a una plataforma de videojuegos y explicamos cómo utilizar el servicio Backblaze para realizar copias de seguridad de nuestro equipo.]]></summary></entry><entry><title type="html">Podcast 3x02</title><link href="https://vidageek.com/3/2023/10/03/podcast-3x02.html" rel="alternate" type="text/html" title="Podcast 3x02" /><published>2023-10-03T00:00:00+00:00</published><updated>2023-10-03T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/10/03/podcast-3x02</id><content type="html" xml:base="https://vidageek.com/3/2023/10/03/podcast-3x02.html"><![CDATA[<h1 id="charlando-sobre-iphone-15-macbook-air-financiación-openai-bing-meta-quest-y-más">Charlando sobre iPhone 15, Macbook Air, financiación, OpenAI, Bing, Meta Quest y más</h1>
<p>En el episodio de hoy hablamos de forma distendida sobre varias cosas como el iPhone 15 o el Macbook Air de los cuales Paco es nuevo poseedor (aún en parte). Además hablamos sobre <a href="https://github.com/jzhang38/TinyLlama">TinyLlama</a>, un nuevo LLM “pequeño” de tan sólo 1.1 billones de parámetros.</p>

<p>También os contamos lo nuevo de <a href="https://openai.com/blog/chatgpt-can-now-see-hear-and-speak">OpenAI que ahora puede oír, hablar y ver</a> y de cómo podemos utilizarlo gratis gracias a <a href="https://www.bing.com/?cc=es">Bing</a>.</p>

<p>Meta ha presentado las nuevas <a href="https://www.meta.com/es/quest/quest-3/">Quest 3</a> y han hecho un vídeo en el nos muestran cómo las podemos utilizar para entrar <a href="https://www.youtube.com/watch?v=MVYrJJNdrEg">en una videoconferencia con un avatar fotorrealista</a>. Muy interesante, la verdad.</p>

<hr />
<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Charlando sobre iPhone 15, Macbook Air, financiación, OpenAI, Bing, Meta Quest y más En el episodio de hoy hablamos de forma distendida sobre varias cosas como el iPhone 15 o el Macbook Air de los cuales Paco es nuevo poseedor (aún en parte). Además hablamos sobre TinyLlama, un nuevo LLM “pequeño” de tan sólo 1.1 billones de parámetros.]]></summary></entry><entry><title type="html">Podcast 3x01</title><link href="https://vidageek.com/3/2023/09/25/podcast-3x01.html" rel="alternate" type="text/html" title="Podcast 3x01" /><published>2023-09-25T00:00:00+00:00</published><updated>2023-09-25T00:00:00+00:00</updated><id>https://vidageek.com/3/2023/09/25/podcast-3x01</id><content type="html" xml:base="https://vidageek.com/3/2023/09/25/podcast-3x01.html"><![CDATA[<h1 id="open-interpreter-hablando-con-tu-ordenador">Open Interpreter: Hablando con tu ordenador</h1>

<p>La inteligencia artificial sigue imparable. Hoy vamos a hablar de un nuevo proyecto de código abierto llamado <a href="https://github.com/KillianLucas/open-interpreter">Open Interpreter</a> el cual nos permite “hablar” con nuestro ordenador.</p>

<p><a href="https://github.com/KillianLucas/open-interpreter">Open Interpreter</a> es la respuesta de código abierto al plugin “Code Interpreter” que sacó en la versión plus de ChatGPT. Este plugin permite la creación y ejecución de código en base a una petición, o prompt. Entre otras cosas te permite resolución de problemas matemáticos, análisis y visualización de datos, convertir ficheros a diferentes formatos, y cosas así. No obstante tiene ciertas limitaciones como que opera sin acceso a internet, tiene un set de paquetes previamente instalados limitado, tiene un límite de 2 minutos de ejecución y el estado es eliminado después de la ejecución.</p>

<p>Open Interpreter viene a mejorar todo esto, dando acceso completo a tu PC o Mac de forma que pueda ejecutar código diréctamente en tu equipo y con acceso a internet, eliminando todos esos límites impuestos por ChatGPT. Además, al ser un proyecto open source, puede operar totalmente en local utilizando un LLM que también se ejecute en local. Aunque si queremos que tenga mucha más potencia y conocimiento lo ideal es que utilicemos GPT4. No obstante en este caso estaremos enviando todo lo que hacemos a OpenAI y esto puede suponer un problema de privacidad.</p>

<p>Aquí os vamos a explicar cómo ponerlo en marcha totalmente en local, sin tener que utilizar GPT4. Para ello utilizaremos CodeLlama, un LLM desarrollado por Meta, especializado en programación, que se ejecuta en local y con una licencia bastante abierta.</p>

<h2 id="puesta-en-marcha">Puesta en marcha</h2>

<p>Lo primero que tenemos que realizar es crearnos un entorno de ejecución con Conda. Si bien este paso no es esencial, es muy recomendable. Conda es un gestor de entornos de ejecución de forma que nos crea entornos independientes para cada proyecto. Esto está muy bien ya que muchas veces los proyectos necesitan de versiones específicas de ciertos paquetes o librerías. Para ello Conda crea un entorno de ejecución para cada proyecto aislado de los demas. Si bien aquí no vamos a tratar la instalación de Conda, es algo muy sencillo de realizar haciéndo una búsqueda en internet.</p>

<p>Una vez tengamos conda instalado crearemos un entorno para el proyecto:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ conda create python=3.11 open-interpreter
 $ conda activate open-interpreter
</code></pre></div></div>

<p>El siguiente paso es simplemente instalar open-interpreter con pip:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ pip install open-interpreter
</code></pre></div></div>

<p>Y ya está! Simplemente con esto ya tenemos Open Interpreter instalado. Ahora simplemente tenemos que ejecutar</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ interpreter
</code></pre></div></div>
<p>y seguir los pasos que nos va pidiendo.</p>

<h2 id="gpt4-o-codellama">GPT4 o CodeLlama</h2>

<p>Lo primero que nos pedirá es la clave de API de OpenAI para utilizar GPT4 como motor LLM. Esto es lo más rápido y efectivo puesto que GPT4 es el LLM más potente y capaz hasta la fecha. No obstante tiene ciertas desventajas:</p>
<ul>
  <li>No es gratis</li>
  <li>Todos tus comandos y respuestas serán enviados a OpenAI para procesarlos
Como alternativa podemos usar CodeLlama. Un LLM desarrollado por Meta que podemos ejecutar en local. CodeLlama viene en 3 sabores: 7B, 11B y 34B. Cada número se refiere a los billones de parámetros que tiene el modelo. Como suele ser en estas cosas, cuanto más, mejor. Pero cuanto más, más RAM y potencia de cálculo necesitarás.</li>
</ul>

<p>He hecho pruebas con el más potente (34B aunque muy comprimido) y con GPT4 y claramente GPT4 es mucho más potente y capaz. Aunque en la petición que le hice (generar un fichero excel a partir de un listado de películas en un PDF) no fue capaz de conseguir el objetivo final.</p>

<h2 id="opencore-legacy-patcher">OpenCore Legacy Patcher</h2>

<p>Paco nos ha comentado cómo ha sido posible actualizar su Macbook Pro Retina de 2014 a la última versión de MacOS gracias a <a href="https://dortania.github.io/OpenCore-Legacy-Patcher/">OpenCore Legacy Patcher</a>, un proyecto open source que nos permite crear un instalador de MacOS que engaña al sistema operativo haciéndole creer que se está ejecutando en un hardware soportado.</p>

<p>Dependiendo del hardware que tengamos algos OS serán soportados y otros no. Sin embargo si tu equipo es de 2013 o supuerior suele poder soportar los últimos MacOS hasta la fecha. Quizá haya algunas funcionalidades que no estén disponibles pero generalmente funciona francamente bien.</p>

<hr />

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="3" /><summary type="html"><![CDATA[Open Interpreter: Hablando con tu ordenador]]></summary></entry><entry><title type="html">Podcast 2x14</title><link href="https://vidageek.com/2/2023/07/06/podcast-2x14.html" rel="alternate" type="text/html" title="Podcast 2x14" /><published>2023-07-06T00:00:00+00:00</published><updated>2023-07-06T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/07/06/podcast-2x14</id><content type="html" xml:base="https://vidageek.com/2/2023/07/06/podcast-2x14.html"><![CDATA[<h1 id="hubble-network-revolucionando-la-comunicación-de-dispositivos-iot-desde-el-espacio">Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio</h1>

<p>Hoy vamos a hablar de Hubble Network, una compañía que pretende revolucionar la forma en la que se comunican muchos de nuestros dispositivos, especialmente aquellos relacionados con el Internet de las Cosas (IoT). Estos dispositivos suelen enfrentar un problema importante: la comunicación con Internet, la cual requiere de sistemas costosos en términos de batería y tamaño.</p>

<h2 id="el-desafío-de-la-comunicación-en-dispositivos-iot">El desafío de la comunicación en dispositivos IoT</h2>

<p>Imaginemos dispositivos ubicados en un campo, encargados de monitorear animales o condiciones específicas. Para enviar esta información periódicamente a Internet, se requiere de un sistema de comunicación que, en la mayoría de los casos, resulta costoso en términos de batería y cobertura. Por ejemplo, si utilizáramos un modem GSM o LTE, similar a un teléfono móvil, nos enfrentaríamos a dos problemas principales: el consumo de batería y la cobertura en zonas rurales remotas, donde la señal puede ser escasa o inexistente.</p>

<p>Existen otros sistemas más eficientes energéticamente, como SIGFOX o LORAWAN, pero su despliegue depende de la presencia de repetidores de estos protocolos en las cercanías. En algunas zonas, puede que estos repetidores no estén disponibles.</p>

<h2 id="la-revolución-de-hubble-network">La revolución de Hubble Network</h2>

<p>Es aquí donde Hubble Network busca revolucionar estos sistemas de comunicación de una forma sencilla y eficiente. Esta empresa tiene como objetivo llevar los dispositivos BLE (Bluetooth Low Energy) al espacio. Si estás escuchando este podcast con unos AirPods u otros auriculares inalámbricos, es muy probable que estés utilizando la tecnología BLE, la cual permite una conexión fácil entre estos dispositivos y nuestros móviles.</p>

<p>Hubble Network ha desarrollado un satélite con miles de antenas modificadas para capturar las señales de los dispositivos BLE que, con un firmware específico, transmiten desde la Tierra. Esta capacidad es impresionante, ya que elimina la necesidad de utilizar chips o módems especiales como SIGFOX o LORAWAN. La mayoría de los dispositivos de IoT ya cuentan con un chip BLE, y si no lo tienen, su incorporación resulta increíblemente económica y eficiente.</p>

<p>Por ejemplo, en un proyecto en el que he estado trabajando, se utilizó un sistema similar con un chip BLE de Nordic Semi, capaz de funcionar durante 2 años con una simple pila de botón. Un ejemplo conocido de este sistema es el AirTag de Apple, cuya autonomía también es muy alta.</p>

<h2 id="la-constelación-de-satélites-de-hubble-network">La constelación de satélites de Hubble Network</h2>

<p>Hubble Network planea poner en órbita baja una constelación de satélites que capturarán la información enviada por dispositivos Bluetooth. La empresa ha conseguido una inversión de 20 millones de dólares, lo cual le permitirá lanzar su primer satélite en enero de 2024, gracias a SpaceX, y comenzar a operar su red.</p>

<p>Durante los primeros meses, con un único satélite en órbita, se espera que la captura de datos de los dispositivos ocurra cada 6 horas, el tiempo que tardará en dar una vuelta completa alrededor de nuestro planeta. A pesar de las limitaciones iniciales, esto es un logro impresionante para el inicio de esta ambiciosa empresa. Seguiremos de cerca los avances de Hubble Network y os mantendremos informados sobre su desarrollo.</p>

<p>Si tengo la oportunidad de obtener el kit de desarrollo de esta tecnología, lo utilizaré para explorar su funcionamiento. Tengo muchas ganas de presenciar cómo Hubble Network está transformando la forma en que se comunican los dispositivos IoT desde el espacio.</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Hubble Network: Revolucionando la comunicación de dispositivos IoT desde el espacio]]></summary></entry><entry><title type="html">Podcast 2x13</title><link href="https://vidageek.com/2/2023/06/11/podcast-2x13.html" rel="alternate" type="text/html" title="Podcast 2x13" /><published>2023-06-11T00:00:00+00:00</published><updated>2023-06-11T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/06/11/podcast-2x13</id><content type="html" xml:base="https://vidageek.com/2/2023/06/11/podcast-2x13.html"><![CDATA[<h1 id="la-visión-de-apple">La visión de Apple</h1>
<p>Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.</p>

<p>Y es que las nuevas gafas de Apple definen el futuro de la computación, o como ellos lo han llamado, la computación espacial. Un futuro en el que la pantalla no nos limitará en la interacción sino que podremos ampliarla o reducirla a nuestro antojo. O poner 3 pantallas si queremos.</p>

<p>Finalmente todas las especificaciones filtradas se cumplieron y tenemos unas gafas que tinen una pantalla superior a 4K en cada ojo con una densidad de píxeles superior a los 4000ppp, un procesador M2 junto a un coprocesador R1 que se encarga de la gestión de todos los sensores, que no son pocos. 12 cámaras, 6 micrófonos, seguimiento ocular y seguimiento de manos.</p>

<p>Estas gafas nos permiten crear un entorno virtual junto a nuestro entorno físico e interactuar con el mismo. Para ello no utilizamos controles externos sino que simplemente utilizamos nuestra vista y nuestras manos. Miramos lo que queremos seleccionar y pellizcamos con los dedos.</p>

<p>También tiene una corona digital con la cual controlaremos el nivel de inmersión en el sistema pudiendo ocultar por completo nuestro entorno real.</p>

<p>Además tiene una pantalla exterior en 3D que permite ver una recreación simulada de nuestros ojos de forma que da la sensación de que las gafas son transparentes.</p>

<p>La integración con el ecosistema es espectacular de forma que podemos “sacar” la pantalla de un Macbook y representarla en el espacio.</p>

<p>Lo malo es el precio, a partir de 3500$ más impuestos y sólo se pondrá a la venta en USA a partir del año que viene.</p>

<p>Tenemos muchas ganas de probarlas y veremos si somos capaces con hacernos con unas.</p>

<p>¡Un saludo y hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[La visión de Apple Todos los rumores que hubo previos al lanzamiento de las esperadas gafas de Apple se han cumplido. El pasado lunes 5 de Junio Apple puso sobre la mesa su nueva visión del futuro con un modelo de gafas que parece traído directamente de una película de ciencia ficción.]]></summary></entry><entry><title type="html">Podcast 2x12</title><link href="https://vidageek.com/2/2023/06/03/podcast-2x12.html" rel="alternate" type="text/html" title="Podcast 2x12" /><published>2023-06-03T00:00:00+00:00</published><updated>2023-06-03T00:00:00+00:00</updated><id>https://vidageek.com/2/2023/06/03/podcast-2x12</id><content type="html" xml:base="https://vidageek.com/2/2023/06/03/podcast-2x12.html"><![CDATA[<h1 id="según-esta-filtración-las-gafas-de-apple-tendían-unas-especificaciones-loquísimas">Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas</h1>
<p>Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:</p>

<ul>
  <li>Pantalla Micro-OLED de 1,41 pulgadas para cada ojo</li>
  <li>Resolución 4K en cada ojo</li>
  <li>Densidad de píxeles de 4000 ppi (puntos por pulgada)</li>
  <li>Más de 5000 nits de brillo</li>
  <li>ProMotion display hasta 120hz de refresco</li>
</ul>

<p>En comparación las PlayStation VR2 tienen unas pantallas de 2000x2400 pixeles (frente a 3840x2160 del 4K) y una densidad de píxeles de 850ppi…</p>

<p>Así se explica que hubiera otro rumor que situaba su precio en unos 3000$…</p>

<p>Fuente: <a href="https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter">https://www.macworld.com/article/1935837/apple-reality-headset-display-leak-resolution-brightness.html?utm_source=tldrnewsletter</a></p>

<h3 id="por-cierto-que-el-lunes-a-partir-de-las-1845-hora-española-daremos-cobertura-en-directo-al-evento-de-apple">Por cierto que el lunes a partir de las 18:45 hora española daremos cobertura en directo al evento de Apple.</h3>
<h2 id="suscríbete-a-nuestro-canal-de-youtube-para-verlo-en-directo-httpswwwyoutubecomliveskn2xcvt0lofeatureshareaa">Suscríbete a nuestro canal de YouTube para verlo en directo: <a href="https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share">https://www.youtube.com/live/sKn2Xcvt0Lo?feature=share</a>aa</h2>

<hr />

<h1 id="imagebind-un-embedding-para-enlazarlos-a-todos">ImageBind un embedding para enlazarlos a todos</h1>
<p>Meta sigue dándonos muchas alegrías ya que ha presentado un nuevo modelo de IA que pretende enlazar múltiples y diversos fuentes de datos como:</p>
<ul>
  <li>Audio</li>
  <li>Texto</li>
  <li>Imagen</li>
  <li>Datos de profundidad</li>
  <li>Datos de aceleración</li>
  <li>Mapas de calor</li>
</ul>

<p>Este nuevo modelo multimodal crea unos embeddings que interrelacionan todos los datos aunque sean de diferente tipo. De este modo se le puede pasar un audio de un perro ladrando y encontrar imágenes de perros por ejemplo. Esto abre un nuevo campo en la IA ya que enlazándolo con los grandes modelos de lenguaje LLM nos permitrá una interacción multimodal tremenda.</p>

<p>Además, es de código abierto. Meta nos está sorprendiendo mucho en este campo y dejando atrás esa mala imagen que Facebook consiguió.</p>

<p><a href="https://imagebind.metademolab.com">https://imagebind.metademolab.com</a></p>

<hr />

<h1 id="mitigar-el-riesgo-de-extinción-humana-por-ia-debería-ser-una-prioridad-global">Mitigar el riesgo de extinción humana por IA debería ser una prioridad global</h1>
<p>Esto es lo que han dicho algunas figuras relevantes en el campo de la IA como los ganadores del premio Turing Geoffery Hinton y Yoshua Bengio así como el CEO de OpenAI Sam Altman, y otros ejecutivos de OpenAI como Ilya Sutskever y Mira Murati. Además también lo suscriben el CEO de DeepMind Demis Hassabis o el CEO de Anthropic Dario Amodei, y profesores de la UC Berkely, Stanford y MIT.</p>

<p>Esta vez no han escrito una <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">carta abierta</a> como sucedió en el pasado mes de marzo, sino que simplemente han dicho lo siguiente:</p>

<blockquote>
  <p><em>“Mitigar el riesgo de extinción por la IA debería ser una prioridad global junto con otros riesgos a escala social como las pandemias o las guerras nucleares.”</em></p>
</blockquote>

<p>Más información: <a href="https://www.safe.ai/press-release">https://www.safe.ai/press-release</a></p>

<p>¡Hasta la próxima semana!</p>]]></content><author><name></name></author><category term="2" /><summary type="html"><![CDATA[Según esta filtración, las gafas de Apple tendían unas especificaciones loquísimas Y otro rumor más… por si teníamos pocos, este último te dejará con la boca abierta (o más bien con los ojos abiertos) ya que se han filtrado las especificaciones de lo que serán las gafas de Apple y no tienen competencia… Serían estas:]]></summary></entry></feed>